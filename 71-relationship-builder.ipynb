{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#dependencies\n",
    "\n",
    "#nlp packages\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "#manipulation of tables/arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#internal imports\n",
    "from ssda_nlp.collate import *\n",
    "from ssda_nlp.split_data import *\n",
    "from ssda_nlp.modeling import *\n",
    "from ssda_nlp.model_performance_utils import *\n",
    "from ssda_nlp.xml_parser import *\n",
    "from ssda_nlp.unstructured2markup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def id_unique_individuals(entry_text, entities, record_type):\n",
    "    '''\n",
    "    identifies all unique individuals that appear in an entry (i.e. removing all multiple mentions of the same person)\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model\n",
    "        record_type: simple flag indicating whether records are baptisms, marriages, burials, etc. (this can also be determined\n",
    "        programmatically and may be deprecated later)\n",
    "        \n",
    "        returns: a list of the unique individuals who appear in an entry\n",
    "    '''\n",
    "    \n",
    "    return unique_individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def determine_principals(entry_text, entities, n_principals):\n",
    "    '''\n",
    "    determines the principal of a single-principal event\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model\n",
    "        n_principals: expected number of principals\n",
    "        \n",
    "        returns: the principal(s) of the event in question, or None if no principal can be identified\n",
    "    '''\n",
    "    \n",
    "    entry_text = entry_text.lower()\n",
    "    \n",
    "    if n_principals == 1:        \n",
    "        principals = None\n",
    "        \n",
    "        for index, entity in entities.iterrows():\n",
    "            if entity['pred_label'] == 'PER' and entity['pred_start'] <= 20:\n",
    "                principals = entity['pred_entity']\n",
    "                \n",
    "        if principals == None:            \n",
    "            prox = entry_text.find('oleos')\n",
    "            if prox != -1:\n",
    "                for index, entity in entities.iterrows():\n",
    "                    if entity['pred_label'] == 'PER' and (abs(entity['pred_start'] - prox) <= 10):\n",
    "                        principals = entity['pred_entity']\n",
    "                        \n",
    "        if principals == None:\n",
    "            prox = entry_text.find('nombre')\n",
    "            if prox != -1:\n",
    "                for index, entity in entities.iterrows():\n",
    "                    if entity['pred_label'] == 'PER' and (abs(entity['pred_start'] - prox) <= 10):\n",
    "                        principals = entity['pred_entity']                        \n",
    "        \n",
    "    elif n_principals == 2:\n",
    "        print(\"That number of principals is not supported yet.\")\n",
    "        return None\n",
    "        #process marriage principals\n",
    "    else:\n",
    "        print(\"Invalid number of principals.\")\n",
    "        return None\n",
    "    \n",
    "    return principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def determine_event_date(entry_text, entities, event_type, volume_metadata):\n",
    "    '''\n",
    "    determines the date of a specific event\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model\n",
    "        event_type: this could be either a valid record_type OR a secondary event like a birth\n",
    "        volume_metadata: metadata for the volume that the entry comes from, built by retrieve_volume_metadata\n",
    "        \n",
    "        returns: the date of the event in question, or None if no date can be identified\n",
    "    '''\n",
    "    date = None\n",
    "    \n",
    "    if event_type != volume_metadata[\"type\"]:        \n",
    "        primary_event_date = determine_event_date(entry_text, entities, event_type, volume_metadata)\n",
    "        for index, entity in entities.iterrows():\n",
    "            if entity['pred_label'] == 'DATE' and entity['pred_entity'] != primary_event_date:\n",
    "                date = entity['pred_entity']\n",
    "    \n",
    "    elif volume_metadata[\"type\"] == \"baptism\":\n",
    "        entry_length = len(entry_text)\n",
    "        \n",
    "        for index, entity in entities.iterrows():\n",
    "            if entity['pred_label'] == 'DATE' and entity['pred_start'] <= (entry_length / 3):\n",
    "                date = entity['pred_entity']        \n",
    "                \n",
    "    else:\n",
    "        date = \"That event type is not supported yet.\"\n",
    "        \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def determine_event_location(entry_text, entities, event_type, volume_metadata):\n",
    "    '''\n",
    "    determines the location of a specific event\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model\n",
    "        event_type: this could be either a valid record_type OR a secondary event like a birth\n",
    "        volume_metadata: metadata for the volume that the entry comes from, built by retrieve_volume_metadata\n",
    "        \n",
    "        returns: the location of the event in question, or None if no date can be identified\n",
    "    '''\n",
    "    location = None\n",
    "    \n",
    "    if event_type == volume_metadata[\"type\"]:\n",
    "        location = volume_metadata[\"institution\"]    \n",
    "    else:\n",
    "        location = \"That event type is not supported yet.\"\n",
    "    \n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def identify_cleric(entry_text, entities):\n",
    "    '''\n",
    "    identifies the cleric(s) associated with a sacramental entry\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model        \n",
    "        \n",
    "        returns: the associated cleric(s), or None if no date can be identified\n",
    "    '''\n",
    "    clerics = None\n",
    "    \n",
    "    for index, entity in entities.iterrows():\n",
    "            if ((entity['pred_label'] == 'PER') and ((len(entry_text) - entity['pred_end']) <= 10) and (len(entry_text) > 100)):\n",
    "                clerics = entity['pred_entity']\n",
    "            #going to keep this condition for now, but it can create false positives when long, incorrect entities are extracted\n",
    "            #from short and/or garbled entries\n",
    "            elif (entity['pred_entity'] != None) and (len(entry_text) - entity['pred_end'] <= 2) and (entity['pred_label'] == 'PER'):\n",
    "                clerics = entity['pred_entity']                                                 \n",
    "                \n",
    "    if clerics == None:\n",
    "        pvs_label = None\n",
    "        pvs_end = None\n",
    "        for index, entity in entities.iterrows():\n",
    "            if entity['pred_label'] == 'PER' and pvs_label == 'DATE' and (entity['pred_start'] - pvs_end) <= 15:\n",
    "                clerics = entity['pred_entity']                \n",
    "            pvs_label = entity['pred_label']\n",
    "            pvs_end = entity['pred_end']\n",
    "    \n",
    "    if clerics == None:\n",
    "        entry_text = entry_text.lower()\n",
    "        for index, entity in entities.iterrows():\n",
    "            if entity['pred_label'] == 'PER' and entry_text.find(\"cura\", entity['pred_start'] + len(entity['pred_entity'])) != -1 and ((entry_text.find(\"cura\", entity['pred_start'] + len(entity['pred_entity']))) - entity['pred_end']) <= 15:\n",
    "                clerics = entity['pred_entity']                \n",
    "    \n",
    "    return clerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def build_event(entry_text, entities, event_type, principals):\n",
    "    '''\n",
    "    builds out relationships related to a baptism or burial event\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model\n",
    "        \n",
    "        returns: structured representation of these relationships, including (but not necessarily limited to)\n",
    "        the event's principal, the date of the event, the location of the event, and the associated cleric\n",
    "    '''   \n",
    "    \n",
    "    date = determine_event_date(entry_text, entities, event_type)\n",
    "    location = determine_event_location(entry_text, entities, event_type)\n",
    "    cleric = identify_cleric(entry_text, entities)\n",
    "    \n",
    "    return event_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def build_relationships(entry_text, entities, path_to_volume_xml):\n",
    "    '''\n",
    "    Master function that will combine all helper functions built above\n",
    "        entry_text: the full text of a single entry, ported directly from spaCy to ensure congruity\n",
    "        entities: entities of all kinds extracted from that entry by an NER model\n",
    "        record_type: simple flag indicating whether records are baptisms, marriages, burials, etc. (this can also be determined\n",
    "        programmatically and may be deprecated later)\n",
    "            \n",
    "        returns: structured data (specific format to be named later) containing all relationships extracted\n",
    "    '''\n",
    "    #unique_individuals = id_unique_indviduals(entry_text, entities, record_type)\n",
    "    \n",
    "    volume_metadata = retrieve_metadata(path_to_volume_xml)\n",
    "    \n",
    "    if volume_metadata[\"type\"] == \"baptism\":\n",
    "        principals = determine_principals(entry_text, entities, 1)\n",
    "        #event_relationships = build_event(entry_text, entities, \"baptism\", principals)               \n",
    "        #interpersonal_relationships = process_interpersonal(entry_text, entities)\n",
    "        #characteristics = process_characteristics(entry_text, entities, interpersonal_relationships)        \n",
    "    elif volume_metadata[\"type\"] == \"marriage\":        \n",
    "        #process marriage record\n",
    "        print(\"That record type is not supported yet.\")\n",
    "        return None\n",
    "    elif volume_metadata[\"type\"] == \"burial\":\n",
    "        #process burial record\n",
    "        print(\"That record type is not supported yet.\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"That record type is not supported yet.\")\n",
    "        return None\n",
    "    \n",
    "    #code that turns pieces defined above into well-formed relationships\n",
    "    \n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model and entry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models\\\\mat_baut_1\\\\vocab\\\\lexemes.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8944e605011d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#no_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrained_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/mat_baut_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"es\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Fall_2020\\SSDA\\ssda-nlp\\ssda_nlp\\modeling.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(model, language, verbose)\u001b[0m\n\u001b[0;32m     36\u001b[0m     '''\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# load existing spaCy model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loaded model '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# path to model data directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(self, path, exclude, disable)\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[1;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"vocab\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;31m# Split to support file names like meta.json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mdeserializers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta.json\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrsly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         deserializers[\"vocab\"] = lambda p: self.vocab.from_disk(\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m         ) and _fix_pretrained_vectors_name(self)\n\u001b[0;32m    933\u001b[0m         deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(\n",
      "\u001b[1;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001b[1;32m-> 1203\u001b[1;33m                        opener=self._opener)\n\u001b[0m\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[1;34m(self, name, flags, mode)\u001b[0m\n\u001b[0;32m   1056\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0o666\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0o777\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models\\\\mat_baut_1\\\\vocab\\\\lexemes.bin'"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "trained_model = load_model('models/mat_baut_1', language=\"es\", verbose='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "path_to_transcription = \"transcriptions\\\\15834.xml\"\n",
    "demo_df = parse_xml_v2(path_to_transcription)\n",
    "demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "volume_metadata = retrieve_volume_metadata(path_to_transcription)\n",
    "print(volume_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model to entry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "ent_preds_df, metrics_df, per_ent_metrics = test_model(trained_model, demo_df, \"entry_no\", \"text\", score_model=False)\n",
    "ent_preds_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine_principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "for index, row in demo_df.iterrows():\n",
    "    entry_no = row['entry_no']\n",
    "    entry_text = row['text']\n",
    "    entities = ent_preds_df.loc[ent_preds_df['entry_no'] == entry_no]\n",
    "    print(determine_principals(entry_text, entities, 1))\n",
    "    if index > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine_event_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "for index, row in demo_df.iterrows():    \n",
    "    entry_no = row['entry_no']\n",
    "    entry_text = row['text']\n",
    "    entities = ent_preds_df.loc[ent_preds_df['entry_no'] == entry_no]\n",
    "    print(determine_event_date(entry_text, entities, volume_metadata[\"type\"], volume_metadata))\n",
    "    if index > 25:\n",
    "        break       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function currently fails to find a date for a substantial proportion (~20%) of entries because dates aren't being accurately extracted from the original. If this problem continues as the model improves and more entry data is incorporated into the sample, we'll need to add the post-processing capacity to bracket missing event dates by looking at entries on either side of the entry missing a date. Regardless, we will also need to add the post-processing capacity to convert these textual dates into numerical ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine_event_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "for index, row in demo_df.iterrows():    \n",
    "    entry_no = row['entry_no']\n",
    "    entry_text = row['text']\n",
    "    entities = ent_preds_df.loc[ent_preds_df['entry_no'] == entry_no]\n",
    "    print(determine_event_location(entry_text, entities, volume_metadata[\"type\"], volume_metadata))\n",
    "    if index > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identify_cleric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "for index, row in demo_df.iterrows():    \n",
    "    entry_no = row['entry_no']\n",
    "    entry_text = row['text']\n",
    "    entities = ent_preds_df.loc[ent_preds_df['entry_no'] == entry_no]\n",
    "    print(identify_cleric(entry_text, entities))\n",
    "    if index > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
