{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31-collate-xml-entities-spans\n",
    "> Structuring the data to be compatible with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes as input two separate dataframes, one containing parsed volume XML from the Spatial Historian and the other containing entity references, also from Spatial Historian. The input dataframes are merged using folio IDs as an index, then entry text is searched for the referenced entities to generate spans defining their location. The final output dataframe contains the following columns: vol_id, vol_titl, fol_id, entry_no, text (these first five from parsed XML), entity, label (from entity references), start, and end (for spans, generated by this code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo dummy data\n",
    "The expected dataframe formats to be passed in appear as below.  One is the parsed XML from Spatial Historial.  The other contains entity references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "volume_ids = [\"1\", \"1\", \"1\", \"2\", \"3\"]\n",
    "volume_titles = [\"First book\"] * 3 + [\"Second book\", \"Third book\"]\n",
    "folio_ids = [\"101\", \"102\", \"102\", \"103\", \"104\"]\n",
    "entry_numbers = [\"101-1\", \"102-1\", \"102-2\", \"103-1\", \"104-1\"]\n",
    "texts = [\"Daniel wrote some code.\", \"Tyrion ate some food and Tyrion drank some water.\", \"Tyrion went to sleep while Daniel kept working.\", \"The rabbit ran away.\", \"One day the rabbit would be eaten by Tyrion.\"]\n",
    "names = [\"Tyrion\", \"Daniel\", \"rabbit\"]\n",
    "types = [\"Person\"] * len(names)\n",
    "sources = [\"skhgrhb-0102; hfiheiuhf-0104\", \"fkheuihfi-0101; aehuihifh-0102\", \"hfuiehlfiw-0103; afefafaef-0104\"]\n",
    "\n",
    "xml_dict = {\"vol_id\": volume_ids, \"vol_titl\": volume_titles, \"fol_id\": folio_ids, \"entry_no\": entry_numbers, \"text\": texts}\n",
    "entity_dict = {\"Entity Type\": types, \"Name\": names, \"Source Associator\": sources}\n",
    "\n",
    "xml_df = pd.DataFrame(xml_dict)\n",
    "ent_df = pd.DataFrame(entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_id</th>\n",
       "      <th>vol_titl</th>\n",
       "      <th>fol_id</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>101</td>\n",
       "      <td>101-1</td>\n",
       "      <td>Daniel wrote some code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-1</td>\n",
       "      <td>Tyrion ate some food and Tyrion drank some water.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-2</td>\n",
       "      <td>Tyrion went to sleep while Daniel kept working.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Second book</td>\n",
       "      <td>103</td>\n",
       "      <td>103-1</td>\n",
       "      <td>The rabbit ran away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Third book</td>\n",
       "      <td>104</td>\n",
       "      <td>104-1</td>\n",
       "      <td>One day the rabbit would be eaten by Tyrion.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vol_id     vol_titl fol_id entry_no  \\\n",
       "0      1   First book    101    101-1   \n",
       "1      1   First book    102    102-1   \n",
       "2      1   First book    102    102-2   \n",
       "3      2  Second book    103    103-1   \n",
       "4      3   Third book    104    104-1   \n",
       "\n",
       "                                                text  \n",
       "0                            Daniel wrote some code.  \n",
       "1  Tyrion ate some food and Tyrion drank some water.  \n",
       "2    Tyrion went to sleep while Daniel kept working.  \n",
       "3                               The rabbit ran away.  \n",
       "4       One day the rabbit would be eaten by Tyrion.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Source Associator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>skhgrhb-0102; hfiheiuhf-0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>fkheuihfi-0101; aehuihifh-0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>hfuiehlfiw-0103; afefafaef-0104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entity Type    Name                Source Associator\n",
       "0      Person  Tyrion     skhgrhb-0102; hfiheiuhf-0104\n",
       "1      Person  Daniel   fkheuihfi-0101; aehuihifh-0102\n",
       "2      Person  rabbit  hfuiehlfiw-0103; afefafaef-0104"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "ent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating spans for Spacy input\n",
    "Spacy requires that the integer location of the entities within the texts are known and identified for the training set.  With the entry `Chickpea is a dog`, the spans returned should return the start and ending points (specifically one past the ending location - Pythonic referencing) of the entity.  Here, the entity is `Chickpea`, and the start location should be 0, and the end location should be 8.  The following two functions achieves this for the Spatial Historian entities.\n",
    "\n",
    "`genAltEnts` additionally checks for anomalies in representation of the data in Spatial Historian.  Sometimes, an entity `Chickpea` may appear as `C hickpea` or `Ch#ckpea` if certain parts of the name are ambiguous.  This function checks for these scenarios by generating all possible forms of the entity with spaces and pound signs inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def genAltEnts(entity):\n",
    "    '''\n",
    "    Function genAltEnts: This function takes an entity and generates all possible forms of it with errant spaces or pound\n",
    "    symbols mixed in.\n",
    "        Inputs: entity: String of entity\n",
    "        Output: list of possible forms of the entity with spaces and pound signs inserted\n",
    "    '''\n",
    "    alt_ents = []\n",
    "    \n",
    "    #individual characters replaced by ' '\n",
    "    for i in range(1, len(entity)):\n",
    "        alt_ents.append((entity[:i]) + ' ' + entity[i:])\n",
    "            \n",
    "    #individual characters replaced by #\n",
    "    for j in range(1, len(entity)):\n",
    "        alt_ents.append((entity[:j]) + '#' + entity[j + 1:])\n",
    "    \n",
    "    #missing last name\n",
    "    #if (len(entity.split(' ')) > 1):\n",
    "        #alt_ents.append(entity[:entity.rfind(' ')])\n",
    "    \n",
    "    return alt_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#search entry for each instance of an entity reference\n",
    "\n",
    "def generateSpans(entry, entity):\n",
    "    '''\n",
    "    Function generateSpans: This function takes individual entries and entities from the merged dataframes and \n",
    "    returns a list containing a span defining each instance in which that entity appears in that entry \n",
    "    (spans are returned as nested lists).\n",
    "        Inputs: entry: String of entry text\n",
    "                entity: String of entity whose span is to be located within the text\n",
    "        Output: nested list of spans for the entity for each place it appears within the entry.\n",
    "    '''\n",
    "    curr_index = 0\n",
    "    spans = []\n",
    "    entity_len = len(entity)    \n",
    "   \n",
    "    #Scroll through each entry and find each instance of the entity and append spans if not already present\n",
    "    while entry.find(entity, curr_index) != -1:\n",
    "        entity_start = entry.find(entity, curr_index)\n",
    "        span = [entity_start, entity_start + entity_len]\n",
    "        curr_index = span[1]\n",
    "        if span not in spans:\n",
    "            spans.append(span)\n",
    "            \n",
    "    #If no spans are present        \n",
    "    if spans == []:\n",
    "        alts = genAltEnts(entity)\n",
    "        for alt in alts:\n",
    "            alt_len = len(alt)\n",
    "            while entry.find(alt, curr_index) != -1:\n",
    "                entity_start = entry.find(alt, curr_index)\n",
    "                span = [entity_start, entity_start + alt_len]\n",
    "                curr_index = span[1]\n",
    "                if span not in spans:\n",
    "                    spans.append(span)\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing: `generateSpans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 19]]\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: [[15, 19]]\n",
    "\n",
    "print(generateSpans(\"This is just a test!\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 10], [11, 13]]\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: [[8, 10], [11, 13]]\n",
    "#Repeated entities are a fairly rare corner case for our purposes, but I wanted to account for it.\n",
    "\n",
    "print(generateSpans(\"What is it it appears multiple times?\", \"it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: []\n",
    "#This (entities not appearing in the entry) should not happen, but if so the desired behavior is not to build a row in the final\n",
    "#dataframe.\n",
    "\n",
    "print(generateSpans(\"It isn't here!\", \"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data into the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions take the input dataframes and convert them into lists for further processing (it's likely completely possible to do this all using dataframes, but I'm more used to interacting with lists). parseEntities takes the entity reference dataframe as input and expects three columns labeled \"Entity Type\", \"Name\", and \"Source Associator\". parseXML takes the parsed XML dataframe as input and expects five columns labeled \"vol_id\", \"vol_titl\", \"fol_id\", \"entry_no\", and \"text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parseEntities(df_entities):\n",
    "    '''\n",
    "    Function parseEntities: takes entity reference dataframe as input, returns each column as a list for ease of processing\n",
    "    and boils source references down to unique portion\n",
    "        Inputs: df_entities: pandas DataFrame with columns \"Entity Type\", \"Name\", and \"Source Associator\"\n",
    "        Outputs: 3 lists: entity types, entities, and parsed source associators\n",
    "    '''\n",
    "    types = df_entities[\"Entity Type\"].tolist()\n",
    "    names = df_entities[\"Name\"].tolist()\n",
    "    \n",
    "    sources = []\n",
    "    for source_assoc in df_entities[\"Source Associator\"]:\n",
    "        temp = []\n",
    "        refs = source_assoc.split(';')\n",
    "        for ref in refs:\n",
    "            source = ref[ref.find('-') + 1:]\n",
    "            while source[0] == '0':\n",
    "                source = source[1:]\n",
    "            if (not source in temp):\n",
    "                temp.append(source)\n",
    "        sources.append(temp)\n",
    "    \n",
    "    return types, names, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parseManualEntities(csv_entities):\n",
    "    '''\n",
    "    Function parseManualEntities: takes manually produced entity reference csv as input and produces same outputs\n",
    "    as those of parseEntities\n",
    "    Inputs: csv_entities: path to csv containing two columns, one with folio ids and one with a list of names appearing on\n",
    "    each folio, separated by semicolons\n",
    "    Outputs: 3 lists: entity types, entities, and parsed source associatos\n",
    "    '''\n",
    "    csv = open(csv_entities, 'r', encoding=\"utf-8\")\n",
    "    folios = []\n",
    "    people = []\n",
    "    \n",
    "    for line in csv:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        if \"Folio\" in line:\n",
    "            continue\n",
    "        folio, temp = line.split(',')\n",
    "        ppl = temp.split(';')\n",
    "        folios.append(folio)\n",
    "        people.append(ppl)\n",
    "    \n",
    "    csv.close()\n",
    "    \n",
    "    names = []\n",
    "    sources = []\n",
    "    \n",
    "    for x in range(len(folios)):\n",
    "        for person in people[x]:\n",
    "            if not (person in names):\n",
    "                names.append(person)\n",
    "                temp = [folios[x]]\n",
    "                sources.append(temp)\n",
    "            else:\n",
    "                loc = names.index(person)\n",
    "                if not (folios[x] in sources[loc]):\n",
    "                    sources[loc].append(folios[x])\n",
    "                \n",
    "    types = [\"PER\"] * len(names)\n",
    "    \n",
    "    return types, names, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parseXML(df_XML):\n",
    "    '''\n",
    "    Function parseXML: takes volume XML dataframe as input and returns each column as a list\n",
    "        Inputs: df_XML: pandas DataFrame with columns \"vol_id\", 'vol_titl', 'fol_id', 'entry_no', and 'text'\n",
    "        Outputs: 5 lists corresonding to each column: volume ids, volume titles, folio ids, entry numbers, and entry texts\n",
    "    '''\n",
    "    volume_ids = df_XML[\"vol_id\"].tolist()\n",
    "    volume_titles = df_XML[\"vol_titl\"].tolist()\n",
    "    folio_ids = df_XML[\"fol_id\"].tolist()\n",
    "    entry_numbers = df_XML[\"entry_no\"].tolist()\n",
    "    entry_texts = df_XML[\"text\"].tolist()\n",
    "    \n",
    "    return volume_ids, volume_titles, folio_ids, entry_numbers, entry_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `genEntryIDs` function returns a list of the IDs for all entries in which an input entity appears on an input folio. It also takes as input the full lists of folio IDs, entry IDs, and entry texts from the parsed XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def genEntryIDs(folio_ids, entry_ids, texts, entity, entity_folio):\n",
    "    '''\n",
    "    Function genEntryIDs: returns of list of IDs for all entries in which an input entity appears in a folio.\n",
    "        Inputs: Sets of lists, where the index of each list correponds to the information in every other list index (i.e., each list is a column of a dataframe)\n",
    "                folio_ids: list of folio IDs to be processed\n",
    "                entry_ids: list of IDs for each entry\n",
    "                texts: list of entry texts \n",
    "                entity: entity to be found in the data\n",
    "                entity_folio: folio in which to look for the entity\n",
    "        Outputs: 5 lists corresonding to each column: volume ids, volume titles, folio ids, entry numbers, and entry texts\n",
    "    '''\n",
    "    \n",
    "    #find the indices of the entity folio of interest\n",
    "    np_fol = np.array(folio_ids)\n",
    "    folio_indices = np.where(np_fol == entity_folio)[0]    \n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    #Determine if the entity is in the folios if interest and append entry_id if so\n",
    "    for entries in folio_indices:\n",
    "        if texts[entries].find(entity) != -1:\n",
    "            matches.append(entry_ids[entries])\n",
    "            \n",
    "    #Check the to see if maybe the entity has unusual representation with # or ' ' inserted     \n",
    "    if matches == []:\n",
    "        alts = genAltEnts(entity)\n",
    "        for alt in alts:\n",
    "            for entries in folio_indices:\n",
    "                if (texts[entries].find(alt) != -1) and (entry_ids[entries] not in matches):\n",
    "                    matches.append(entry_ids[entries])                    \n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing: `genEntryIDs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#dummy data to quickly test genEntryIDs\n",
    "\n",
    "folio_ids = [\"1\", \"1\", \"1818\", \"1818\"]\n",
    "entry_ids = [\"1-1\", \"1-2\", \"1818-1\", \"1818-2\"]\n",
    "texts = [\"Tyrion ate a bone.\", \"Daniel ate a sandwich.\", \"Tyrion climbed a tree.\", \"Tyrion is sleeping.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-2']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: ['1-2']\n",
    "\n",
    "entity = \"Daniel\"\n",
    "entity_folio = \"1\"\n",
    "\n",
    "genEntryIDs(folio_ids, entry_ids, texts, entity, entity_folio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-1']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: ['1-1']\n",
    "\n",
    "entity = \"Tyrion\"\n",
    "entity_folio = \"1\"\n",
    "\n",
    "genEntryIDs(folio_ids, entry_ids, texts, entity, entity_folio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1818-1', '1818-2']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: ['1818-1','1818-2']\n",
    "\n",
    "entity = \"Tyrion\"\n",
    "entity_folio = \"1818\"\n",
    "\n",
    "genEntryIDs(folio_ids, entry_ids, texts, entity, entity_folio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "#expected output: []\n",
    "#again, this (entities not appearing on the folio in question) shouldn't happen, but if it does we don't want to build a row\n",
    "#in the final dataframe\n",
    "\n",
    "entity = \"Michael Jordan\"\n",
    "entity_folio = \"1818\"\n",
    "\n",
    "genEntryIDs(folio_ids, entry_ids, texts, entity, entity_folio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring joining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below use the functions defined above to combine the two input dataframes and generate spans. For the time being, they use the dummy data at the top of this document.  Any work using these functions requires the format of the dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#parsing dummy data (back) into lists\n",
    "#start here with real data\n",
    "\n",
    "vol_ids, vol_titls, fol_ids, entry_nos, entry_texts = parseXML(xml_df)\n",
    "ent_types, ent_names, ent_fols = parseEntities(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#building entry ID lists for entities\n",
    "\n",
    "ent_entries = [[]] * len(ent_names)\n",
    "index = 0\n",
    "\n",
    "for entity in ent_names:    \n",
    "    for folio in ent_fols[index]:        \n",
    "        ent_entries[index] = ent_entries[index] + (genEntryIDs(fol_ids, entry_nos, entry_texts, entity, folio))        \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#creating merged lists\n",
    "\n",
    "out_volume_ids = []\n",
    "out_volume_titles = []\n",
    "out_folio_ids = []\n",
    "out_entry_numbers = []\n",
    "out_entry_texts = []\n",
    "out_entity_names = []\n",
    "out_span_starts = []\n",
    "out_span_ends = []\n",
    "out_labels = []\n",
    "\n",
    "index = 0 #this is clumsy and could probably be implemented better with numpy, \n",
    "#but it's to protect against multiple instances of the same entity name\n",
    "\n",
    "for entity in ent_names:\n",
    "    for entry in ent_entries[index]:        \n",
    "        folio_id = entry[:entry.find('-')]        \n",
    "        volume_id = vol_ids[fol_ids.index(folio_id)]\n",
    "        volume_title = vol_titls[fol_ids.index(folio_id)]        \n",
    "        entry_text = entry_texts[entry_nos.index(entry)]        \n",
    "        label = ent_types[ent_names.index(entity)]\n",
    "        \n",
    "        spans = generateSpans(entry_text, entity)        \n",
    "        for span in spans:            \n",
    "            out_volume_ids.append(volume_id)\n",
    "            out_volume_titles.append(volume_title)\n",
    "            out_folio_ids.append(folio_id)\n",
    "            out_entry_numbers.append(entry)\n",
    "            out_entry_texts.append(entry_text)\n",
    "            out_entity_names.append(entity)\n",
    "            out_span_starts.append(span[0])\n",
    "            out_span_ends.append(span[1])\n",
    "            out_labels.append(label)\n",
    "        \n",
    "    index += 1\n",
    "    \n",
    "collated_dict = {\"vol_id\": out_volume_ids, \"vol_titl\": out_volume_titles, \"fol_id\": out_folio_ids, \"entry_no\": out_entry_numbers, \"text\": out_entry_texts, \"entity\": out_entity_names, \"start\": out_span_starts, \"end\": out_span_ends, \"label\": out_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_id</th>\n",
       "      <th>vol_titl</th>\n",
       "      <th>fol_id</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>text</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-1</td>\n",
       "      <td>Tyrion ate some food and Tyrion drank some water.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-1</td>\n",
       "      <td>Tyrion ate some food and Tyrion drank some water.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-2</td>\n",
       "      <td>Tyrion went to sleep while Daniel kept working.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Third book</td>\n",
       "      <td>104</td>\n",
       "      <td>104-1</td>\n",
       "      <td>One day the rabbit would be eaten by Tyrion.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>101</td>\n",
       "      <td>101-1</td>\n",
       "      <td>Daniel wrote some code.</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-2</td>\n",
       "      <td>Tyrion went to sleep while Daniel kept working.</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Second book</td>\n",
       "      <td>103</td>\n",
       "      <td>103-1</td>\n",
       "      <td>The rabbit ran away.</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Third book</td>\n",
       "      <td>104</td>\n",
       "      <td>104-1</td>\n",
       "      <td>One day the rabbit would be eaten by Tyrion.</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vol_id     vol_titl fol_id entry_no  \\\n",
       "0      1   First book    102    102-1   \n",
       "1      1   First book    102    102-1   \n",
       "2      1   First book    102    102-2   \n",
       "3      3   Third book    104    104-1   \n",
       "4      1   First book    101    101-1   \n",
       "5      1   First book    102    102-2   \n",
       "6      2  Second book    103    103-1   \n",
       "7      3   Third book    104    104-1   \n",
       "\n",
       "                                                text  entity  start  end  \\\n",
       "0  Tyrion ate some food and Tyrion drank some water.  Tyrion      0    6   \n",
       "1  Tyrion ate some food and Tyrion drank some water.  Tyrion     25   31   \n",
       "2    Tyrion went to sleep while Daniel kept working.  Tyrion      0    6   \n",
       "3       One day the rabbit would be eaten by Tyrion.  Tyrion     37   43   \n",
       "4                            Daniel wrote some code.  Daniel      0    6   \n",
       "5    Tyrion went to sleep while Daniel kept working.  Daniel     27   33   \n",
       "6                               The rabbit ran away.  rabbit      4   10   \n",
       "7       One day the rabbit would be eaten by Tyrion.  rabbit     12   18   \n",
       "\n",
       "    label  \n",
       "0  Person  \n",
       "1  Person  \n",
       "2  Person  \n",
       "3  Person  \n",
       "4  Person  \n",
       "5  Person  \n",
       "6  Person  \n",
       "7  Person  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "collated_df = pd.DataFrame(collated_dict)\n",
    "collated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final code to generate joined dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function combines the previous four cells so that dataframe conversion can be performed in other notebooks.  `collate_frames` is the top-level function that should be called to join the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def collate_frames(xml_df, ent_df):\n",
    "    '''\n",
    "    Function collate_frames: combines XML dataframe and entity dataframe to generate final dataframe with spans\n",
    "        Inputs: xml_df: pandas DataFrame with columns \"vol_id\", 'vol_titl', 'fol_id', 'entry_no', and 'text'\n",
    "                ent_df: pandas DataFrame with columns \"Entity Type\", \"Name\", and \"Source Associator\"    \n",
    "        Outputs: a joined, collated dataframe of xml_df and ent_df\n",
    "    '''\n",
    "    #parsing input frames into lists\n",
    "    vol_ids, vol_titls, fol_ids, entry_nos, entry_texts = parseXML(xml_df)\n",
    "    ent_types, ent_names, ent_fols = parseEntities(ent_df)\n",
    "    \n",
    "    #building entry ID lists for entities\n",
    "    ent_entries = [[]] * len(ent_names)\n",
    "    index = 0\n",
    "\n",
    "    for entity in ent_names:    \n",
    "        for folio in ent_fols[index]:        \n",
    "            ent_entries[index] = ent_entries[index] + (genEntryIDs(fol_ids, entry_nos, entry_texts, entity, folio))        \n",
    "        index += 1   \n",
    "        \n",
    "    #creating collated lists\n",
    "    out_volume_ids = []\n",
    "    out_volume_titles = []\n",
    "    out_folio_ids = []\n",
    "    out_entry_numbers = []\n",
    "    out_entry_texts = []\n",
    "    out_entity_names = []\n",
    "    out_span_starts = []\n",
    "    out_span_ends = []\n",
    "    out_labels = []\n",
    "\n",
    "    index = 0 #this is clumsy and could probably be implemented better with numpy, \n",
    "    #but it's to protect against multiple instances of the same entity name\n",
    "\n",
    "    for entity in ent_names:\n",
    "        for entry in ent_entries[index]:            \n",
    "            folio_id = entry[:entry.find('-')]        \n",
    "            volume_id = vol_ids[fol_ids.index(folio_id)]\n",
    "            volume_title = vol_titls[fol_ids.index(folio_id)]        \n",
    "            entry_text = entry_texts[entry_nos.index(entry)]        \n",
    "            label = ent_types[ent_names.index(entity)]\n",
    "\n",
    "            spans = generateSpans(entry_text, entity)            \n",
    "            for span in spans:            \n",
    "                out_volume_ids.append(volume_id)\n",
    "                out_volume_titles.append(volume_title)\n",
    "                out_folio_ids.append(folio_id)\n",
    "                out_entry_numbers.append(entry)\n",
    "                out_entry_texts.append(entry_text)\n",
    "                out_entity_names.append(entity)\n",
    "                out_span_starts.append(span[0])\n",
    "                out_span_ends.append(span[1])\n",
    "                out_labels.append(label)\n",
    "\n",
    "        index += 1\n",
    "        \n",
    "    #The loop below addresses a rare corner case that could result in tokens being mapped to multiple entities, which spaCy\n",
    "    #does not allow. This occurs when one entity string in a given entry is a substring of another that appears in the same\n",
    "    #entry.\n",
    "    \n",
    "    spanned_entries = [] #list of unique entries with entity spans\n",
    "    spanned_tokens_per_entry = [] #list of indices that appear in spans for each entry\n",
    "    i = 0\n",
    "    while i < len(out_entry_numbers):\n",
    "        if out_entry_numbers[i] in spanned_entries:            \n",
    "            for k in range(out_span_starts[i], out_span_ends[i]):\n",
    "                if k in spanned_tokens_per_entry[spanned_entries.index(out_entry_numbers[i])]:                    \n",
    "                    del out_volume_ids[i]\n",
    "                    del out_volume_titles[i]\n",
    "                    del out_folio_ids[i]\n",
    "                    del out_entry_numbers[i]\n",
    "                    del out_entry_texts[i]\n",
    "                    del out_entity_names[i]\n",
    "                    del out_span_starts[i]\n",
    "                    del out_span_ends[i]\n",
    "                    del out_labels[i]\n",
    "                    i -= 1\n",
    "                    break\n",
    "                else:\n",
    "                    spanned_tokens_per_entry[spanned_entries.index(out_entry_numbers[i])].append(k)            \n",
    "        else:\n",
    "            spanned_entries.append(out_entry_numbers[i])\n",
    "            temp = []\n",
    "            for j in range(out_span_starts[i], out_span_ends[i]):\n",
    "                temp.append(j)\n",
    "            spanned_tokens_per_entry.append(temp)\n",
    "        i += 1    \n",
    "    \n",
    "    collated_dict = {\"vol_id\": out_volume_ids, \"vol_titl\": out_volume_titles, \"fol_id\": out_folio_ids, \"entry_no\": out_entry_numbers, \"text\": out_entry_texts, \"entity\": out_entity_names, \"start\": out_span_starts, \"end\": out_span_ends, \"label\": out_labels}\n",
    "    \n",
    "    collated_df = pd.DataFrame(collated_dict)\n",
    "    return collated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def manual_collate(xml_df, ent_csv):    \n",
    "    #parsing input frames into lists\n",
    "    vol_ids, vol_titls, fol_ids, entry_nos, entry_texts = parseXML(xml_df)\n",
    "    ent_types, ent_names, ent_fols = parseManualEntities(ent_csv)\n",
    "    \n",
    "    #building entry ID lists for entities\n",
    "    ent_entries = [[]] * len(ent_names)\n",
    "    index = 0\n",
    "\n",
    "    for entity in ent_names:    \n",
    "        for folio in ent_fols[index]:        \n",
    "            ent_entries[index] = ent_entries[index] + (genEntryIDs(fol_ids, entry_nos, entry_texts, entity, folio))        \n",
    "        index += 1   \n",
    "        \n",
    "    #creating collated lists\n",
    "    out_volume_ids = []\n",
    "    out_volume_titles = []\n",
    "    out_folio_ids = []\n",
    "    out_entry_numbers = []\n",
    "    out_entry_texts = []\n",
    "    out_entity_names = []\n",
    "    out_span_starts = []\n",
    "    out_span_ends = []\n",
    "    out_labels = []\n",
    "\n",
    "    index = 0 #this is clumsy and could probably be implemented better with numpy, \n",
    "    #but it's to protect against multiple instances of the same entity name\n",
    "\n",
    "    for entity in ent_names:\n",
    "        for entry in ent_entries[index]:            \n",
    "            folio_id = entry[:entry.find('-')]        \n",
    "            volume_id = vol_ids[fol_ids.index(folio_id)]\n",
    "            volume_title = vol_titls[fol_ids.index(folio_id)]        \n",
    "            entry_text = entry_texts[entry_nos.index(entry)]        \n",
    "            label = ent_types[ent_names.index(entity)]\n",
    "\n",
    "            spans = generateSpans(entry_text, entity)            \n",
    "            for span in spans:            \n",
    "                out_volume_ids.append(volume_id)\n",
    "                out_volume_titles.append(volume_title)\n",
    "                out_folio_ids.append(folio_id)\n",
    "                out_entry_numbers.append(entry)\n",
    "                out_entry_texts.append(entry_text)\n",
    "                out_entity_names.append(entity)\n",
    "                out_span_starts.append(span[0])\n",
    "                out_span_ends.append(span[1])\n",
    "                out_labels.append(label)\n",
    "\n",
    "        index += 1\n",
    "        \n",
    "    #The loop below addresses a rare corner case that could result in tokens being mapped to multiple entities, which spaCy\n",
    "    #does not allow. This occurs when one entity string in a given entry is a substring of another that appears in the same\n",
    "    #entry.\n",
    "    \n",
    "    spanned_entries = [] #list of unique entries with entity spans\n",
    "    spanned_entities_per_entry = [] #list of unique entity name strings in each entry\n",
    "    \n",
    "    for entry_number in out_entry_numbers:\n",
    "        if not (entry_number in spanned_entries):\n",
    "            spanned_entries.append(entry_number)\n",
    "            spanned_entities_per_entry.append([])            \n",
    "    \n",
    "    for i in range(len(out_entity_names)):\n",
    "        entry_pos = spanned_entries.index(out_entry_numbers[i])\n",
    "        if not (out_entity_names[i] in spanned_entities_per_entry[entry_pos]):\n",
    "            spanned_entities_per_entry[entry_pos].append(out_entity_names[i])            \n",
    "    \n",
    "    output_pos = 0\n",
    "    while output_pos < len(out_entity_names):\n",
    "        entity_entry = spanned_entries.index(out_entry_numbers[output_pos])\n",
    "        for spanned_entity in spanned_entities_per_entry[entity_entry]:\n",
    "            if (out_entity_names[output_pos] in spanned_entity) and (out_entity_names[output_pos] != spanned_entity):\n",
    "                del out_volume_ids[output_pos]\n",
    "                del out_volume_titles[output_pos]\n",
    "                del out_folio_ids[output_pos]\n",
    "                del out_entry_numbers[output_pos]\n",
    "                del out_entry_texts[output_pos]\n",
    "                del out_entity_names[output_pos]\n",
    "                del out_span_starts[output_pos]\n",
    "                del out_span_ends[output_pos]\n",
    "                del out_labels[output_pos]\n",
    "                output_pos -= 1\n",
    "                break\n",
    "        output_pos += 1\n",
    "    \n",
    "    collated_dict = {\"vol_id\": out_volume_ids, \"vol_titl\": out_volume_titles, \"fol_id\": out_folio_ids, \"entry_no\": out_entry_numbers, \"text\": out_entry_texts, \"entity\": out_entity_names, \"start\": out_span_starts, \"end\": out_span_ends, \"label\": out_labels}\n",
    "    \n",
    "    collated_df = pd.DataFrame(collated_dict)\n",
    "    return collated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "gh = [1,2,3,4,4,5]\n",
    "\n",
    "for element in gh:\n",
    "    print(gh.index(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_id</th>\n",
       "      <th>vol_titl</th>\n",
       "      <th>fol_id</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>text</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-1</td>\n",
       "      <td>Tyrion ate some food and Tyrion drank some water.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-1</td>\n",
       "      <td>Tyrion ate some food and Tyrion drank some water.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-2</td>\n",
       "      <td>Tyrion went to sleep while Daniel kept working.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Third book</td>\n",
       "      <td>104</td>\n",
       "      <td>104-1</td>\n",
       "      <td>One day the rabbit would be eaten by Tyrion.</td>\n",
       "      <td>Tyrion</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>101</td>\n",
       "      <td>101-1</td>\n",
       "      <td>Daniel wrote some code.</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>First book</td>\n",
       "      <td>102</td>\n",
       "      <td>102-2</td>\n",
       "      <td>Tyrion went to sleep while Daniel kept working.</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Second book</td>\n",
       "      <td>103</td>\n",
       "      <td>103-1</td>\n",
       "      <td>The rabbit ran away.</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Third book</td>\n",
       "      <td>104</td>\n",
       "      <td>104-1</td>\n",
       "      <td>One day the rabbit would be eaten by Tyrion.</td>\n",
       "      <td>rabbit</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vol_id     vol_titl fol_id entry_no  \\\n",
       "0      1   First book    102    102-1   \n",
       "1      1   First book    102    102-1   \n",
       "2      1   First book    102    102-2   \n",
       "3      3   Third book    104    104-1   \n",
       "4      1   First book    101    101-1   \n",
       "5      1   First book    102    102-2   \n",
       "6      2  Second book    103    103-1   \n",
       "7      3   Third book    104    104-1   \n",
       "\n",
       "                                                text  entity  start  end  \\\n",
       "0  Tyrion ate some food and Tyrion drank some water.  Tyrion      0    6   \n",
       "1  Tyrion ate some food and Tyrion drank some water.  Tyrion     25   31   \n",
       "2    Tyrion went to sleep while Daniel kept working.  Tyrion      0    6   \n",
       "3       One day the rabbit would be eaten by Tyrion.  Tyrion     37   43   \n",
       "4                            Daniel wrote some code.  Daniel      0    6   \n",
       "5    Tyrion went to sleep while Daniel kept working.  Daniel     27   33   \n",
       "6                               The rabbit ran away.  rabbit      4   10   \n",
       "7       One day the rabbit would be eaten by Tyrion.  rabbit     12   18   \n",
       "\n",
       "    label  \n",
       "0  Person  \n",
       "1  Person  \n",
       "2  Person  \n",
       "3  Person  \n",
       "4  Person  \n",
       "5  Person  \n",
       "6  Person  \n",
       "7  Person  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "collate_frames(xml_df, ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Spacy input format from dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy requires the data to be a list of tuples.  Each tuple should contain the text as a string, and a dictionary.  The dictionary should have the word 'entities' as a key, and the values should be a list of tuples which contain information about the entities.  This information will be of the form: `(span_start, span_end, Entity_type)`.  The `genSpacyInput` function performs this functionality using the dataframe as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def genSpaCyInput(df):\n",
    "    '''\n",
    "    Function genSpaCyInput:function takes a dataframe with columns/contents as above and transforms it into a list of tuples, each consisting of raw text \n",
    "    paired with a dictionary of entities that appear in that text, for input into spaCy. \n",
    "        Inputs: df: dataframe with columns 'text', 'label', 'start', 'end'\n",
    "        Outputs: data in SpaCy format\n",
    "    '''\n",
    "    text = df[\"text\"].tolist()\n",
    "    label = df[\"label\"].tolist()\n",
    "    start = df[\"start\"].tolist()\n",
    "    end = df[\"end\"].tolist()    \n",
    "    \n",
    "    #build list of unique entries and list of empty annotation dictionaries for each\n",
    "    u_txt = []\n",
    "    annot_ls = []\n",
    "    \n",
    "    for tx in text:\n",
    "        if not (tx in u_txt):\n",
    "            u_txt.append(tx)\n",
    "            annot_ls.append({\"entities\":[]})\n",
    "            \n",
    "    #populate annotation dictionaries\n",
    "    for i in range(len(label)):\n",
    "        pos = u_txt.index(text[i])        \n",
    "        annot_ls[pos][\"entities\"].append((int(start[i]), int(end[i]), label[i]))       \n",
    "        \n",
    "    #build list of tuples\n",
    "    tuples = []    \n",
    "    for i in range(len(u_txt)):\n",
    "        tuples.append((u_txt[i], annot_ls[i]))       \n",
    "    \n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tyrion ate some food and Tyrion drank some water.',\n",
       "  {'entities': [(0, 6, 'Person'), (25, 31, 'Person')]}),\n",
       " ('Tyrion went to sleep while Daniel kept working.',\n",
       "  {'entities': [(0, 6, 'Person'), (27, 33, 'Person')]}),\n",
       " ('One day the rabbit would be eaten by Tyrion.',\n",
       "  {'entities': [(37, 43, 'Person'), (12, 18, 'Person')]}),\n",
       " ('Daniel wrote some code.', {'entities': [(0, 6, 'Person')]}),\n",
       " ('The rabbit ran away.', {'entities': [(4, 10, 'Person')]})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "genSpaCyInput(collated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-efficient df to Spacy format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty unassuming, but this is actually the function that just takes the two frames and returns spaCy input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def frames_to_spacy(xml_df, ent_df):\n",
    "    df = collate_frames(xml_df, ent_df)\n",
    "    return genSpaCyInput(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 31-collate-xml-entities-spans.ipynb.\n",
      "Converted 41-generic-framework-for-spacy-training.ipynb.\n",
      "Converted 42-initial-model.ipynb.\n",
      "Converted data-preprocessing.ipynb.\n",
      "Converted markup-to-spacy.ipynb.\n",
      "Converted unstructured-to-markup.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
