{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp validation_visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "> 1. Rather than applying single-volume models to that volume, I think that what makes the most sense here will be to use the best-performing \"everything\" model based on your earlier benchmarking and then apply that to different transcriptions.\n",
    "2. It looks like there are a bunch of checks nested under the isEnslaved check that don't need to be there. Specifically, I think that everything after the enslaver ethnicity check should be un-indented back out to be in line with the isEnslaved check. Am I missing something there? (edited) \n",
    "    - Given the structure of the code I'm not immediately sure how hasWrongEthAssgnt_cler (e.g.) can be so high with isEnslaved low, so it's entirely possible that I am missing something.\n",
    "    - My theory is that there's just some unintended interaction based on the current code structure that is inflating hasWrongEthAssgnt_cler, though, and I think that it'll be eliminated by popping that whole block of code back out and into a separate iteration through entry_people.\n",
    "4. Better encapsuate / separate birth related checks\n",
    "5. Check problem with hasWrongEths for Cleric\n",
    "6. Uncoupled parents is probably incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#dependencies\n",
    "\n",
    "#nlp packages\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "#manipulation of tables/arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import difflib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "#internal imports\n",
    "from ssda_nlp.collate import *\n",
    "from ssda_nlp.split_data import *\n",
    "from ssda_nlp.modeling import *\n",
    "from ssda_nlp.model_performance_utils import *\n",
    "from ssda_nlp.xml_parser import *\n",
    "from ssda_nlp.unstructured2markup import *\n",
    "from ssda_nlp.utility import *\n",
    "from ssda_nlp.relationships import *\n",
    "from ssda_nlp.full_volume import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "COLOR = 'grey'\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "def val_vis_bar(validation_list):\n",
    "    #Set up the figure\n",
    "    plt.figure(figsize=(15,10))\n",
    "    title_font = 30\n",
    "    label_font = 22\n",
    "    tick_font = 15\n",
    "    colors_array = ['g']*17 + ['r']*8\n",
    "    \n",
    "    #Set up the variables\n",
    "    val1 = validation_list[0]\n",
    "    objects = val1.keys()\n",
    "    y_pos = np.arange(len(objects))\n",
    "    performance = [0]*y_pos\n",
    "    \n",
    "    #Gather each validation dictionary from each entry into a summed var\n",
    "    for i in range(len(validation_list)):\n",
    "        entry = validation_list[i]\n",
    "        vals = list(entry.values())\n",
    "\n",
    "        performance = [sum(x) for x in zip(performance, vals)]\n",
    "\n",
    "    #Plot the final results\n",
    "    plt.bar(y_pos, performance, align='center', alpha=0.5, color=colors_array)\n",
    "    plt.xticks(ticks=y_pos, labels=objects, rotation=75, fontsize=tick_font)\n",
    "    plt.xlabel('Checks', fontsize=label_font)\n",
    "    plt.ylabel('Total Number of Validation Flags', fontsize=label_font)\n",
    "    plt.title('Full Volume Validation Checks', fontsize=title_font)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239746\n",
      "Loaded model 'models/239746'\n",
      "Entities extracted.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'baptism_princ' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c7721518672d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmy_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"transcriptions\\\\\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelTemp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".xml\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmy_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelTemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpeople\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoCategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_volume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_trans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mval_vis_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MetaFolder\\SSDA\\ssda-nlp\\ssda_nlp\\full_volume.py\u001b[0m in \u001b[0;36mprocess_volume\u001b[1;34m(path_to_transcription, path_to_model)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mverbosity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[0mentry_validation_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry_people\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry_places\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muncategorized_characteristics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misVerbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[0mvalidation_dict_ALL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry_validation_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MetaFolder\\SSDA\\ssda-nlp\\ssda_nlp\\full_volume.py\u001b[0m in \u001b[0;36mvalidate_entry\u001b[1;34m(entry_entities, entry_people, entry_places, entry_events, uncategorized_characteristics, isVerbose, entry_type)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mhasPrincipal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaptism_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'principal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'NoneType'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;31m#is the principal an infant? ##############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mprinc_age\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaptism_princ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprinc_age\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'infant'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0misInfant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'baptism_princ' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "models_list = [\"15834\", \"166470\", \"239746\"] #\"exhaustive_models\", \"mat_baut_1\", \"port01\", \"st_aug_bapt_2\"]\n",
    "models_list.reverse()\n",
    "#row names: people, places, events, json_path, entities, noCategory, validation_list\n",
    "num_rows = 7\n",
    "num_models = len(models_list)\n",
    "cols = np.zeros((num_rows,num_models))\n",
    "\n",
    "for idx, modelTemp in enumerate(models_list):\n",
    "    #\"transcriptions\\\\15834.xml\", \"models/15834\"\n",
    "    print(modelTemp)\n",
    "    my_trans = \"transcriptions\\\\\" + str(modelTemp) + \".xml\"\n",
    "    my_dir = \"models/\" + str(modelTemp)\n",
    "    people, places, events, json_path, entities, noCategory, validation_list = process_volume(my_trans, my_dir)\n",
    "    print(\"--------------------------------------\")\n",
    "    val_vis_bar(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12-ssda-xml-parser.ipynb.\n",
      "Converted 31-collate-xml-entities-spans.ipynb.\n",
      "Converted 33-split-data.ipynb.\n",
      "Converted 41-generic-framework-for-spacy-training.ipynb.\n",
      "Converted 42-initial-model.ipynb.\n",
      "Converted 51-data-preprocessing.ipynb.\n",
      "Converted 52-unstructured-to-markup.ipynb.\n",
      "Converted 53-markup-to-spatial-historian.ipynb.\n",
      "Converted 54-utility-functions.ipynb.\n",
      "Converted 61-prodigy-output-training-demo.ipynb.\n",
      "Converted 62-full-model-application-demo.ipynb.\n",
      "Converted 63-pt-model-training.ipynb.\n",
      "Converted 64-es-model-training.ipynb.\n",
      "Converted 65-all-annotations-model-training.ipynb.\n",
      "Converted 66-es-guatemala-model-training.ipynb.\n",
      "Converted 67-death-and-birth-records-together.ipynb.\n",
      "Converted 70-exhaustive-training.ipynb.\n",
      "Converted 71-relationship-builder.ipynb.\n",
      "Converted 72-full-volume-processor.ipynb.\n",
      "Converted 73-table-output.ipynb.\n",
      "Converted 74-validation-visuals.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
