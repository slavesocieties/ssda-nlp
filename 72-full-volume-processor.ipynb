{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp full_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#dependencies\n",
    "\n",
    "#nlp packages\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "#manipulation of tables/arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import difflib\n",
    "\n",
    "#internal imports\n",
    "from ssda_nlp.collate import *\n",
    "from ssda_nlp.split_data import *\n",
    "from ssda_nlp.modeling import *\n",
    "from ssda_nlp.model_performance_utils import *\n",
    "from ssda_nlp.xml_parser import *\n",
    "from ssda_nlp.unstructured2markup import *\n",
    "from ssda_nlp.utility import *\n",
    "from ssda_nlp.relationships import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def check_unassigned(entities, isVerbose=0):\n",
    "    char_df = entities[(entities['pred_label'] == 'CHAR')]\n",
    "    char_df = copy.deepcopy(char_df[char_df['assigned'] == False])\n",
    "    rel_df = entities[(entities['pred_label'] == 'REL')]\n",
    "    rel_df = copy.deepcopy(rel_df[rel_df['assigned'] == False])\n",
    "\n",
    "    unassigned_df = char_df.append(rel_df)\n",
    "    unassigned_df.sort_values(by='index', inplace = True)\n",
    "    unassigned_df.drop(['index'], axis=1, inplace = True)\n",
    "    unassigned_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    if isVerbose:\n",
    "        print(\"entities:\")\n",
    "        display(entities.head(1))\n",
    "        print(entities.shape)\n",
    "        print(\"------------------------------------------------\")\n",
    "        \n",
    "        print(\"Unassigned CHAR/RELs found:\")\n",
    "        print(\"char_df shape: \" + str(char_df.shape))\n",
    "        print(\"rel_df shape: \" + str(rel_df.shape))\n",
    "        print(\"unassigned_df shape: \" + str(unassigned_df.shape))\n",
    "        print(\"------------------------------------------------\")\n",
    "\n",
    "        print(\"unassigned_df\")\n",
    "        if unassigned_df.shape[0] < 1:\n",
    "            print(\"No unassigned characteristics or relationships found...\")\n",
    "        else:\n",
    "            display(unassigned_df.head())\n",
    "\n",
    "        print(\"noCategory\")\n",
    "        if noCategory.shape[0] < 1:\n",
    "            print(\"No characteristics without categories found...\")\n",
    "        else:\n",
    "            display(noCategory.head())\n",
    "            \n",
    "    return unassigned_df\n",
    "\n",
    "def check_lengths(name_list, idx, idx2):\n",
    "    name1 = name_list[idx]\n",
    "    name2 = name_list[idx2]\n",
    "    if len(name1)<=(len(name2)+1) and len(name1)>=(len(name2)-1):\n",
    "        my_ratio = int(difflib.SequenceMatcher(None, name1, name2).ratio()*100)\n",
    "        if my_ratio > 80:\n",
    "            #Then these could potentially be the same name but with small differences\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "\n",
    "#Original pseudo code for validation:\n",
    "\n",
    "#if entry_type == \"baptism\":\n",
    "        #is there a baptism event?\n",
    "        #if so:\n",
    "            #does baptism event have a complete date?\n",
    "            #does baptism event have a location?\n",
    "        \n",
    "        #is there an identified cleric?\n",
    "        #is there an identified principal?\n",
    "        #if so:\n",
    "            #are principal's godparent(s) identified?\n",
    "        #if so, and if principal is an infant:                \n",
    "            #are principal's parent(s) identified?\n",
    "            #is there a birth event?\n",
    "            #if so:\n",
    "                #does birth event have a complete date?\n",
    "                #does birth event have a location?\n",
    "        #if so, and if principal is enslaved:\n",
    "            #is principal's enslaver identified?\n",
    "            \n",
    "        #other questions re people:\n",
    "        #are there any entities labeled PER who do not have an explicit role in the baptism (e.g. principal, cleric, parent, enslaver, etc.)\n",
    "        #are there likely couples (e.g. parents, godparents) not explicitly flagged as such\n",
    "        #are there any people with very similar names that still appear separately\n",
    "        \n",
    "        #questions re characteristics:\n",
    "        #are there characteristics that were not categorized\n",
    "        #are there characteristics or relationships that were not assigned\n",
    "        #for ethnicities that were assigned, confirm that they were *not* assigned to slaveholders or clerics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def validate_entry(entry_entities, entry_people, entry_places, entry_events, uncategorized_characteristics, isVerbose = 0, entry_type = \"baptism\"):\n",
    "    '''\n",
    "    analyzes data extracted from a single ecclesiastical entry to assess accuracy of automated entity and relationship extraction\n",
    "        entry_type: baptism, marriage, or burial\n",
    "        entry_entities: df containing all entities extracted from entry (with assignment status)\n",
    "        entry_people: list of dictionaries, each containing people who appear in entry\n",
    "        entry_places: list of dictionaries, each containing places that appear in entry\n",
    "        entry_events: list of dictionaries, each containing events that appear in entry\n",
    "        \n",
    "        returns: dictionary in which key-value pairs encode various details regarding performance of automation\n",
    "    '''\n",
    "    \n",
    "    validation_dict = {}\n",
    "    \n",
    "    #Reinitialize all booleans\n",
    "    #Original base checks related to the event\n",
    "    isBaptism=0; isDateComplete=0; hasLocation=0; hasCleric=0; hasPrincipal=0; \n",
    "    hasRelations=0; hasGodparents=0; hasEnslaver=0;\n",
    "    isInfant=0; hasParents=0; isBirthEvent=0;\n",
    "    isBirthEvent=0; isDateComplete_birth=0; hasLocation_birth=0;\n",
    "    isEnslaved=0; similarNames=0;\n",
    "    #\"Extra\" checks related to people\n",
    "    hasWrongEthAssgnt_ensl = 0; hasWrongEthAssgnt_cler = 0; hasUncatChars = 0; hasUnassgnEnts = 0\n",
    "    hasUncoupledParents = 0; hasUncoupledGodparents = 0; hasUnrelatedPersons=0\n",
    "    \n",
    "    my_keys = ['isBaptism', 'isDateComplete', 'hasLocation', 'hasCleric', 'hasPrincipal',\n",
    "              'hasEnslaver', 'isEnslaved', 'hasRelations', 'hasGodparents', \n",
    "              'isInfant', 'hasParents', 'isBirthEvent', 'isDateComplete_birth', 'hasLocation_birth', \n",
    "              'hasUnrelatedPersons', 'hasUncoupledParents', 'hasUncoupledGodparents','similarNames', \n",
    "              'hasWrongEthAssgnt_ensl', 'hasWrongEthAssgnt_cler', 'hasUncatChars', 'hasUnassgnEnts']\n",
    "    \n",
    "    if isVerbose:\n",
    "        print(\"Entry entities:\")\n",
    "        display(entry_entities.head())\n",
    "        print(\"Entry people:\")\n",
    "        display(entry_people)\n",
    "        print(\"Entry places:\")\n",
    "        display(entry_places)\n",
    "        print(\"Entry events:\")\n",
    "        display(entry_events)\n",
    "        #print(\"Uncategorized characteristics:\") #This is a dataframe\n",
    "    \n",
    "    if entry_type == \"baptism\":\n",
    "        #is there a baptism event? ##############################################################################\n",
    "        baptism_event = {} #Initialization\n",
    "        for bapt_idx in range(len(entry_events)):\n",
    "            isBaptism = entry_events[bapt_idx].get('type')=='baptism'\n",
    "            if isBaptism:\n",
    "                baptism_event = entry_events[bapt_idx]\n",
    "                break\n",
    "        \n",
    "        #if so:\n",
    "        if isBaptism:\n",
    "            #does baptism event have a complete date? #########################################################################\n",
    "            event_date = baptism_event.get('date')\n",
    "            isDateComplete = ( ('?' in event_date) ) # Ex unfinished date: '????-??-22'\n",
    "            #does baptism event have a location? ##############################################################################\n",
    "            event_location = baptism_event.get('location')\n",
    "            hasLocation = entry_places is not None and (len(entry_places)>0)\n",
    "            \n",
    "        #is there an identified cleric? ##############################################################################\n",
    "        hasCleric = not (type(baptism_event.get('cleric'))=='NoneType')\n",
    "            \n",
    "        #is there an identified principal? ##############################################################################\n",
    "        hasPrincipal = not (type(baptism_event.get('principal'))=='NoneType')\n",
    "            \n",
    "        #if so:\n",
    "        if hasCleric and hasPrincipal:\n",
    "            principal_PID = baptism_event.get('principal')\n",
    "            cleric_PID = baptism_event.get('cleric')\n",
    "            \n",
    "            #Loop through to find the principal's entry in entry_people\n",
    "            baptism_princ = '' #Initialization\n",
    "            for princ_idx in range(len(entry_people)):\n",
    "                foundPrinc = principal_PID in entry_people[princ_idx].get('id')\n",
    "                #Need to do \"in\" because, as per the first case, the listed PID is actually 2 PIDs appended together (separated by a ;)\n",
    "                if foundPrinc:\n",
    "                    baptism_princ = entry_people[princ_idx]\n",
    "                    break                \n",
    "            \n",
    "            #is the principal an infant? ##############################################################################\n",
    "            princ_age = baptism_princ.get('age')\n",
    "            if princ_age == 'infant': \n",
    "                isInfant = 1 \n",
    "            \n",
    "            #are principal's godparent(s) identified? ##################################################################\n",
    "            count_godparents = 0\n",
    "            godparents_list = []\n",
    "            count_parents = 0\n",
    "            parents_list = []\n",
    "            relations = baptism_princ.get('relationships')\n",
    "            if relations is not None:\n",
    "                hasRelations = 1\n",
    "                for rel_idx in range(len(relations)):\n",
    "                    if relations[rel_idx].get('relationship_type')=='godparent':\n",
    "                        hasGodparents = 1 \n",
    "                        godparents_list.append(relations[rel_idx].get('related_person'))\n",
    "                        count_godparents += 1\n",
    "                    if (relations[rel_idx].get('relationship_type')=='parent') and (isInfant):\n",
    "                        hasParents = 1 \n",
    "                        parents_list.append(relations[rel_idx].get('related_person'))\n",
    "                        count_parents += 1\n",
    "                    if relations[rel_idx].get('relationship_type')=='enslaver':\n",
    "                        hasEnslaver = 1\n",
    "                        print(\"Enslaver found.  This should lead to a true for isEnslaved\")\n",
    "                        print(relations)\n",
    "                        print(\"------------------\")\n",
    "\n",
    "            #are there likely couples (e.g. parents, godparents) not explicitly flagged as such\n",
    "            if count_godparents>1:\n",
    "                for godparent in godparents_list:\n",
    "                    relations = [person.get('relationships') for person in entry_people if person.get('id')==godparent]\n",
    "                    if relations is not None: \n",
    "                        for rel_idx in range(len(relations)):\n",
    "                            if relations[0][rel_idx].get('relationship_type')=='husband' or relations[0][rel_idx].get('relationship_type')=='wife':\n",
    "                                #They are coupled to someone else\n",
    "                                pass\n",
    "                            else:\n",
    "                                hasUncoupledGodparents = 1\n",
    "                del relations\n",
    "                \n",
    "            if count_parents>1:\n",
    "                for parent in parents_list:\n",
    "                    relations = [person.get('relationships') for person in entry_people if person.get('id')==parent]\n",
    "                    if relations is not None: \n",
    "                        for rel_idx in range(len(relations)):\n",
    "                            if relations[0][rel_idx].get('relationship_type')=='husband' or relations[0][rel_idx].get('relationship_type')=='wife':\n",
    "                                pass\n",
    "                            else:\n",
    "                                hasUncoupledParents = 1\n",
    "                                ################################################\n",
    "                                ################################################\n",
    "                                ################################################\n",
    "                                print(\"Contains uncoupled parents:\")\n",
    "                                print(relations)\n",
    "                                print(\"-------------------------\")\n",
    "                                ################################################\n",
    "                                ################################################\n",
    "                                ################################################\n",
    "                del relations\n",
    "            \n",
    "        status = [\"propiedad\", \"escrava\", \"escravos\", \"esclabo\", \"esclaba\", \"escl.a\", \"escl.o\", \"clavo\", \"clava\", \"escl\", \"escl.\", \"escl.s\", \"clabo\", \"claba\", \"esc.va\", \"esc.ba\", \"esc.vo\", \"escvo\", \"esclavo\", \"esclava\", \"escva\", \"esc.bo\", \"esclabos\", \"esclavos\", \"esc.os\", \"esc.a\", \"esc.o\", \"libre\", \"esc.s\", \"esco\", \"esca\"]\n",
    "        if baptism_princ.get('status') is not None:\n",
    "            print(\"Printing principal status:\")\n",
    "            print(baptism_princ.get('status'))\n",
    "            print(\"---------------------\")\n",
    "            for term in status:\n",
    "                if term in baptism_princ.get('status'):\n",
    "                    isEnslaved = 1\n",
    "                    break\n",
    "        ##########################################\n",
    "        if hasEnslaver and not isEnslaved:\n",
    "            print(\"Enslaver found, but thinks principal is not enslaved...\")\n",
    "            print(baptism_princ)\n",
    "            print(\"-------------------------\")\n",
    "        \n",
    "        #IF PRINCIPAL IS AN INFANT:###########################################################################\n",
    "        if hasGodparents and isInfant:\n",
    "            #are principal's parent(s) identified? #Took care of this above\n",
    "            #is there a birth event? ##############################################################################\n",
    "            birth_event = {} #Initialization\n",
    "            if len(entry_events)>1:\n",
    "                for birth_idx in range(len(entry_events)):\n",
    "                    isBirthEvent = entry_events[birth_idx].get('type')=='birth'\n",
    "                    if isBirthEvent:\n",
    "                        birth_event = entry_events[birth_idx]\n",
    "                        #e.g. this assumes there is only one birth event per entry (max)\n",
    "                        break\n",
    "            #if so:\n",
    "            if isBirthEvent:\n",
    "                #does birth event have a complete date? ##################################################################\n",
    "                event_date_birth = birth_event.get('date')\n",
    "                isDateComplete_birth = not ( ('?' in event_date_birth) ) # Unfinished date: '????-??-22'\n",
    "                #does birth event have a location? #######################################################################\n",
    "                event_location_birth = birth_event.get('location')\n",
    "                if (birth_event.get('location') is not None) and (entry_places is not None) and (len(entry_places)>1):\n",
    "                    hasLocation_birth = 1\n",
    "                elif (birth_event.get('location') is not None) or (entry_places is not None) or (len(entry_places)>1):\n",
    "                    hasLocation_birth = 1\n",
    "                    print(\"Dobule check birth location\")\n",
    "                    print(entry_events)\n",
    "                    print(entry_places)\n",
    "                    print(\"--------------------\")\n",
    "                                \n",
    "        name_list = []\n",
    "        firstNameThreshold = 7\n",
    "        #if so, and if principal is enslaved: ##########################################################################\n",
    "        #is principal's enslaver identified? ########################################################################\n",
    "        for person_idx in range(len(entry_people)):\n",
    "                relationships = entry_people[person_idx].get('relationships')\n",
    "                if relationships is not None:\n",
    "                    for relation in relationships:\n",
    "                        #Check if enslaver has been assigned any ethnicities\n",
    "                        if relation.get('relationship_type')=='slave' and (relation.get('ethnicities') is not None) and (isEnslaved):\n",
    "                            hasWrongEthAssgnt_ensl = 1\n",
    "                            break\n",
    "                #Check if cleric has been assigned any ethnithicities\n",
    "                elif (relationships is None) and (entry_people[person_idx].get('id') is cleric_PID) and (entry_people[person_idx].get('ethnicities') is not None):\n",
    "                    hasWrongEthAssgnt_cler = 1\n",
    "                    ################################################\n",
    "                    ################################################\n",
    "                    ################################################\n",
    "                    print(\"Cleric with assigned ethnicities?\")\n",
    "                    print(entry_people[person_idx])\n",
    "                    print(\"-------------------------\")\n",
    "                    ################################################\n",
    "                    ################################################\n",
    "                    ################################################\n",
    "                #Check for people without any role in the event (i.e. no relations, and not the cleric)\n",
    "                elif (relationships is None) and (entry_people[person_idx].get('id') is not cleric_PID):\n",
    "                    hasUnrelatedPersons = 1\n",
    "                    \n",
    "                #are there any people with very similar names that still appear separately\n",
    "                nameTemp = entry_people[person_idx].get('name')\n",
    "                name_list.append(nameTemp)\n",
    "                #1: Short name that could be a first name\n",
    "                #Make a boolean list to flag which names may be first names (based on length)\n",
    "                possibleFirstNames = [name for name in name_list if len(name)<firstNameThreshold]\n",
    "                fullNames = [name for name in name_list if len(name)>firstNameThreshold]\n",
    "                #Check to see if names appear within each other (i.e. is a person double counted)\n",
    "                doubleCountedNames = []\n",
    "                for idx in range(len(possibleFirstNames)):\n",
    "                    doubleCountedNames= doubleCountedNames + ([name for name in fullNames if possibleFirstNames[idx] in name])\n",
    "                if not len(doubleCountedNames)==0:\n",
    "                    #print(\"Possible double count (first name appears in a second instance (full name))\")\n",
    "                    #print(name_list)\n",
    "                    similarNames = 1\n",
    "                #2: Two similarly-sized names, that could be variations (i.e. missing hypens or have #'s for unknown letters')\n",
    "                for name_idx in range(len(name_list)):\n",
    "                    if name_idx==0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        for idx in range(len(name_list)):\n",
    "                            for idx2 in range(len(name_list)-idx-1):\n",
    "                                idx2 = idx2+idx+1\n",
    "                                if check_lengths(name_list, idx, idx2):\n",
    "                                    #print(name_list)\n",
    "                                    similarNames = 1       \n",
    "                                    \n",
    "        #questions re characteristics:\n",
    "        #are there characteristics that were not categorized\n",
    "        num_rowsC, num_colsC = uncategorized_characteristics.shape\n",
    "        if num_rowsC>0:\n",
    "            hasUncatChars = 1\n",
    "        \n",
    "        #are there characteristics or relationships that were not assigned\n",
    "        unassigned_df = check_unassigned(entry_entities)\n",
    "        num_rowsA, num_colsA = unassigned_df.shape\n",
    "        #display(unassigned_df)\n",
    "        if num_rowsA>0:\n",
    "            hasUnassgnEnts = 1\n",
    "    else:\n",
    "        print(\"Entry is not a baptism, and is not yet supported\")\n",
    "        return {}\n",
    "    \n",
    "    my_values = [isBaptism, isDateComplete, hasLocation, hasCleric, hasPrincipal,\n",
    "              hasEnslaver, isEnslaved, hasRelations, hasGodparents, \n",
    "              isInfant, hasParents, isBirthEvent, isDateComplete_birth, hasLocation_birth, \n",
    "              hasUnrelatedPersons, hasUncoupledParents, hasUncoupledGodparents, similarNames, \n",
    "              hasWrongEthAssgnt_ensl, hasWrongEthAssgnt_cler, hasUncatChars, hasUnassgnEnts]\n",
    "    \n",
    "    val_bools = [True if elem==True else False for elem in my_values]\n",
    "    \n",
    "    validation_dict = dict(zip(my_keys,val_bools))\n",
    "    \n",
    "    #if isVerbose:\n",
    "        #print(validation_dict)\n",
    "    \n",
    "    return validation_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def process_volume(path_to_transcription, path_to_model):\n",
    "    '''\n",
    "    runs the transcription of a single volume (formatted according to SSDA markup 2.0 specs) through the ML entity extraction\n",
    "    and rules-based relationship linking pipelines, then formats resulting data for export into SQL\n",
    "        path_to_transcription: path to an XML file containing the transcription of a single volume\n",
    "        path_to_model: path to a spaCy model trained to extract entities from the proper type of volume\n",
    "    \n",
    "        returns: final people, place, and event dictionaries as well as the\n",
    "        path to a JSON file containing volume metadata as well as people, place, and event records\n",
    "    '''\n",
    "    \n",
    "    #retrieve volume metadata and controlled vocabularies\n",
    "    \n",
    "    volume_metadata = retrieve_volume_metadata(path_to_transcription)\n",
    "    images = xml_v2_to_json(path_to_transcription)\n",
    "    vocabularies = retrieve_controlled_vocabularies()\n",
    "    \n",
    "    if volume_metadata[\"country\"] == \"Brazil\":\n",
    "        lang = \"pt\"\n",
    "        language = \"portuguese\"\n",
    "    else:\n",
    "        lang = \"es\"\n",
    "        language = \"spanish\"\n",
    "        \n",
    "    #load and apply trained model\n",
    "    \n",
    "    trained_model = load_model(path_to_model, language=lang, verbose='True')\n",
    "    \n",
    "    entry_df = parse_xml_v2(path_to_transcription)\n",
    "    \n",
    "    ent_preds_df, metrics_df, per_ent_metrics = test_model(trained_model, entry_df, \"entry_no\", \"text\", score_model=False)\n",
    "    print(\"Entities extracted.\")\n",
    "    \n",
    "    #development\n",
    "    #pd.set_option(\"display.max_rows\", 101)\n",
    "    #display(ent_preds_df.head(100))\n",
    "    \n",
    "    #iterate through each entry and build relationships\n",
    "    \n",
    "    people = []\n",
    "    places = []\n",
    "    events = []\n",
    "    \n",
    "    entitiesRunning = pd.DataFrame()\n",
    "    noCategoryRunning = pd.DataFrame()\n",
    "    \n",
    "    validation_dict_ALL = []\n",
    "    \n",
    "    for i in range(len(entry_df.index)):\n",
    "        \n",
    "        entry_no = entry_df['entry_no'][i]\n",
    "        entry_text = entry_df['text'][i]    \n",
    "    \n",
    "        entities = copy.deepcopy(ent_preds_df[ent_preds_df['entry_no'] == entry_no])\n",
    "        \n",
    "        entities[\"assigned\"] = True\n",
    "        \n",
    "        entry_people, entry_places, entry_events, entities, characteristics_df, categorized_characteristics, uncategorized_characteristics = build_entry_metadata(entry_text, entities, path_to_transcription, entry_no)             \n",
    "        \n",
    "        if uncategorized_characteristics.shape[0] > 0:\n",
    "            noCategoryRunning = noCategoryRunning.append(uncategorized_characteristics)\n",
    "        \n",
    "        #FIND ENTITIES THAT ARE UNASSIGNED OR UNCATEGORIZED\n",
    "        entity_index = 0\n",
    "        for ent_data in entities.itertuples():\n",
    "            for char_data in characteristics_df.itertuples():\n",
    "                char_index = 0\n",
    "                #characteristic is not categorized:\n",
    "                if (char_data.category == None) and (ent_data.pred_start == char_data.pred_start) and (ent_data.pred_entity == char_data.pred_entity):\n",
    "                    continue #Already dealth with\n",
    "                #characteristic is categorized but not assigned\n",
    "                elif (ent_data.pred_label == char_data.pred_label) and (ent_data.pred_start == char_data.pred_start) and (ent_data.pred_entity == char_data.pred_entity):\n",
    "                    if (char_data.assignment == None):\n",
    "                        entities.at[entity_index, \"assigned\"] = False\n",
    "                char_index += 1\n",
    "            entity_index += 1\n",
    "\n",
    "        entitiesRunning = entitiesRunning.append(entities)  \n",
    "        \n",
    "        verbosity = 0\n",
    "        entry_validation_dict = validate_entry(entities, entry_people, entry_places, entry_events, uncategorized_characteristics, isVerbose = verbosity)\n",
    "        validation_dict_ALL.append(entry_validation_dict)\n",
    "        \n",
    "        people += entry_people\n",
    "        places += entry_places\n",
    "        events += entry_events\n",
    "    \n",
    "    noCategoryRunning.reset_index(drop = True, inplace = True)\n",
    "    noCategoryRunning[\"assigned\"] = False\n",
    "    print(\"Relationships linked.\")\n",
    "    \n",
    "    #disambiguate locations and assign unique ids\n",
    "    \n",
    "    unique_places = []\n",
    "    for place in places:\n",
    "        if (place != None) and (place not in unique_places):\n",
    "            unique_places.append(place)\n",
    "            \n",
    "    for person in people:        \n",
    "        if (person[\"origin\"] != None) and (person[\"origin\"] not in unique_places):\n",
    "            unique_places.append(person[\"origin\"])\n",
    "    \n",
    "    places = []\n",
    "    curr_place = 1\n",
    "    for unique_place in unique_places:\n",
    "        place_record = {\"id\":volume_metadata[\"id\"] + '-L' + str(curr_place), \"location\":unique_place}\n",
    "        places.append(place_record)\n",
    "        curr_place += 1\n",
    "        \n",
    "    #incorporate location ids into event metadata and person records\n",
    "    \n",
    "    for event in events:\n",
    "        location = event[\"location\"]\n",
    "        loc_id = \"unknown\"\n",
    "        if location != None:\n",
    "            for place in places:\n",
    "                if place[\"location\"] == location:\n",
    "                    loc_id = place[\"id\"]\n",
    "        if (loc_id == \"unknown\") and (location != None):\n",
    "            print(\"Failed to find location ID for \" + location)\n",
    "            event[\"location\"] = None\n",
    "        else:\n",
    "            event[\"location\"] = loc_id\n",
    "            \n",
    "        if event[\"location\"] == \"unknown\":\n",
    "            event[\"location\"] = None\n",
    "            \n",
    "    for person in people:\n",
    "        if person[\"origin\"] == None:\n",
    "            continue\n",
    "        \n",
    "        for place in places:\n",
    "            if place[\"location\"] == person[\"origin\"]:\n",
    "                person[\"origin\"] = place[\"id\"]\n",
    "                break\n",
    "        \n",
    "    #bracket missing or incomplete event dates\n",
    "    \n",
    "    incomplete_dates = []\n",
    "    last_year = None\n",
    "    last_month = None\n",
    "    last_day = None\n",
    "    \n",
    "    for e in range(len(events)):\n",
    "        curr_year = events[e][\"date\"][:4]\n",
    "        curr_month = events[e][\"date\"][5:7]\n",
    "        curr_day = events[e][\"date\"][8:]\n",
    "        \n",
    "        #fix incompletely extracted years\n",
    "        if (curr_year != \"????\") and (last_year != None) and (abs(int(curr_year) - int(last_year)) > 1):\n",
    "            if (curr_year[3] == last_year[3]):\n",
    "                curr_year = last_year                \n",
    "            elif (curr_month == \"01\") and (last_month == \"12\"):\n",
    "                curr_year = str(int(last_year) + 1)                \n",
    "            else:\n",
    "                curr_year = last_year\n",
    "            events[e][\"date\"] = curr_year + '-' + curr_month + '-' + curr_day\n",
    "        \n",
    "        if (curr_year == \"????\") or (curr_month == \"??\") or (curr_day == \"??\"):\n",
    "            #logic to assign dates for birth events based on associated baptism\n",
    "            if events[e][\"type\"] == \"birth\":\n",
    "                if (events[e][\"id\"][:events[e][\"id\"].find('E')] == events[e - 1][\"id\"][:events[e - 1][\"id\"].find('E')]) and (events[e - 1][\"type\"] == \"baptism\") and ('?' not in events[e - 1][\"date\"]):\n",
    "                        if (curr_month != \"??\") and (curr_day != \"??\"):\n",
    "                            if (curr_month == \"12\") and (last_month == \"01\"):\n",
    "                                curr_year = str(int(last_year) - 1)                                \n",
    "                            elif (30 * int(last_month) + int(last_day) - 30 * int(curr_month) - int(curr_day)) < 21:\n",
    "                                curr_year = last_year\n",
    "                            events[e][\"date\"] = curr_year + '-' + events[e][\"date\"][5:7] + '-' + events[e][\"date\"][8:]\n",
    "                        elif curr_month != \"??\":\n",
    "                            if (curr_month == \"12\"):\n",
    "                                curr_day = \"01\"\n",
    "                                curr_year = str(int(last_year) - 1)\n",
    "                                events[e][\"date\"] = curr_year + '-' + curr_month + '-' + curr_day + '/' + last_year + '-01-01'\n",
    "                            elif (curr_month == last_month):\n",
    "                                curr_day = \"01\"\n",
    "                                curr_year = last_year\n",
    "                                events[e][\"date\"] = curr_year + '-' + curr_month + '-' + curr_day + '/' + last_year + '-' + last_month + '-' + last_day\n",
    "                            elif int(curr_month) == (int(last_month) - 1):\n",
    "                                curr_day = \"01\"\n",
    "                                curr_year = last_year\n",
    "                                events[e][\"date\"] = curr_year + '-' + curr_month + '-' + curr_day + '/' + last_year + '-' + last_month + '-01'                            \n",
    "                        elif curr_day != \"??\":\n",
    "                            if curr_day <= last_day:\n",
    "                                curr_year = last_year\n",
    "                                curr_month = last_month                                \n",
    "                            else:\n",
    "                                if last_month == \"01\":\n",
    "                                    curr_month = \"12\"\n",
    "                                    curr_year = str(int(last_year) - 1)\n",
    "                                else:\n",
    "                                    curr_month = str(int(last_month) - 1)                                    \n",
    "                                    if len(curr_month) < 2:\n",
    "                                        curr_month = '0' + curr_month\n",
    "                                    curr_year = last_year\n",
    "                            events[e][\"date\"] = curr_year + '-' + curr_month + '-' + curr_day\n",
    "                        else:\n",
    "                            if (last_month == '01') and (int(last_day) < 21):\n",
    "                                curr_year = str(int(last_year) - 1)\n",
    "                                curr_month = \"12\"\n",
    "                                curr_day = str(int(last_day) + 9)                               \n",
    "                            elif int(last_day) < 21:\n",
    "                                curr_year = last_year\n",
    "                                curr_month = str(int(last_month) - 1)\n",
    "                                if len(curr_month) < 2:\n",
    "                                    curr_month = '0' + curr_month\n",
    "                                curr_day = str(int(last_day) + 9)\n",
    "                            else:\n",
    "                                curr_year = last_year\n",
    "                                curr_month = last_month\n",
    "                                curr_day = str(int(last_day) - 20)\n",
    "                                if len(curr_day) < 2:\n",
    "                                    curr_day = '0' + curr_day\n",
    "                            events[e][\"date\"] = curr_year + '-' + curr_month + '-' + curr_day + '/' + last_year + '-' + last_month + '-' + last_day\n",
    "                            \n",
    "            if (curr_year == \"????\") or (curr_month == \"??\") or (curr_day == \"??\"):\n",
    "                incomplete_dates.append(e)\n",
    "        elif last_year == None:\n",
    "            for date in incomplete_dates:\n",
    "                events[date][\"date\"] = complete_date(events[date][\"date\"], None, curr_year + '-' + curr_month + '-' + curr_day)\n",
    "            \n",
    "            incomplete_dates = []\n",
    "            last_year = curr_year\n",
    "            last_month = curr_month\n",
    "            last_day = curr_day\n",
    "        elif (compare_dates(int(curr_year), int(curr_month), int(curr_day), int(last_year), int(last_month), int(last_day)) == '>') or (compare_dates(int(curr_year), int(curr_month), int(curr_day), int(last_year), int(last_month), int(last_day)) == '='):\n",
    "            for date in incomplete_dates:\n",
    "                events[date][\"date\"] = complete_date(events[date][\"date\"], last_year + '-' + last_month + '-' + last_day, curr_year + '-' + curr_month + '-' + curr_day)\n",
    "            \n",
    "            incomplete_dates = []\n",
    "            last_year = curr_year\n",
    "            last_month = curr_month\n",
    "            last_day = curr_day                    \n",
    "    \n",
    "    if last_year != None:\n",
    "        for date in incomplete_dates:\n",
    "            events[date][\"date\"] = complete_date(events[date][\"date\"], last_year + '-' + last_month + '-' + last_day, None)\n",
    "        \n",
    "    #merging any date brackets with equal endpoints\n",
    "    for event in events:\n",
    "        interval = event[\"date\"].split('/')\n",
    "        if (len(interval) == 2) and (interval[0] == interval[1]):\n",
    "            event[\"date\"] == interval[0]            \n",
    "        \n",
    "    print(\"Events configured.\")    \n",
    "    \n",
    "    for person in people:        \n",
    "        #strip titles and/or ranks from names\n",
    "        if person[\"name\"] != None:\n",
    "            name_parts = person[\"name\"].split(' ')\n",
    "\n",
    "            if len(name_parts) >= 2:\n",
    "                while ((name_parts[0].lower() + ' ' + name_parts[1].lower()) in vocabularies[\"titles\"]) or ((name_parts[0].lower() + ' ' + name_parts[1].lower()) in vocabularies[\"ranks\"]):\n",
    "                    if len(name_parts) == 2:\n",
    "                        person[\"name\"] = None\n",
    "                    else:\n",
    "                        person[\"name\"] = name_parts[2]\n",
    "                        for i in range(3, len(name_parts)):\n",
    "                            person[\"name\"] += ' ' + name_parts[i]\n",
    "\n",
    "                    if (name_parts[0].lower() + ' ' + name_parts[1].lower()) in vocabularies[\"titles\"]:\n",
    "                        if person[\"titles\"] != None:\n",
    "                            person[\"titles\"] += ';' + name_parts[0] + ' ' + name_parts[1]\n",
    "                        else:\n",
    "                            person[\"titles\"] = name_parts[0] + ' ' + name_parts[1]\n",
    "                    else:\n",
    "                        if person[\"ranks\"] != None:\n",
    "                            person[\"ranks\"] += ';' + name_parts[0] + ' ' + name_parts[1]\n",
    "                        else:\n",
    "                            person[\"ranks\"] = name_parts[0] + ' ' + name_parts[1]\n",
    "\n",
    "                    if person[\"name\"] == None:\n",
    "                        break\n",
    "                    name_parts = person[\"name\"].split(' ')\n",
    "                    if len(name_parts) < 2:\n",
    "                        break\n",
    "\n",
    "            if person[\"name\"] != None:\n",
    "                while (name_parts[0].lower() in vocabularies[\"titles\"]) or (name_parts[0].lower() in vocabularies[\"ranks\"]):\n",
    "                    if len(name_parts) == 1:\n",
    "                        person[\"name\"] = None\n",
    "                    else:\n",
    "                        person[\"name\"] = name_parts[1]\n",
    "                        for i in range(2, len(name_parts)):\n",
    "                            person[\"name\"] += ' ' + name_parts[i]\n",
    "\n",
    "                    if name_parts[0].lower() in vocabularies[\"titles\"]:\n",
    "                        if person[\"titles\"] != None:\n",
    "                            person[\"titles\"] += ';' + name_parts[0]\n",
    "                        else:\n",
    "                            person[\"titles\"] = name_parts[0]\n",
    "                    else:\n",
    "                        if person[\"ranks\"] != None:\n",
    "                            person[\"ranks\"] += ';' + name_parts[0]\n",
    "                        else:\n",
    "                            person[\"ranks\"] = name_parts[0]\n",
    "\n",
    "                    if person[\"name\"] == None:\n",
    "                        break\n",
    "                    name_parts = person[\"name\"].split(' ')\n",
    "                    \n",
    "    #normalize names and all characteristics\n",
    "    names = []\n",
    "    name_counts = []\n",
    "    ethnonym_vocab = retrieve_json_vocab(\"synonyms.json\", \"ethnonyms\")\n",
    "    phenotype_vocab = retrieve_json_vocab(\"synonyms.json\", \"phenotypes\", language=\"spanish\")\n",
    "    \n",
    "    for person in people:\n",
    "        #normalize characteristics and translate to English\n",
    "        for key in person:\n",
    "            if person[key] == None:\n",
    "                continue\n",
    "            if key == \"name\":\n",
    "                person[key] = normalize_text(person[key], \"synonyms.json\", context=\"name\")\n",
    "                #check extracted name for ethnonyms and/or attributed phenotypes        \n",
    "                if (person[\"name\"] != None) and (person[\"name\"] != normalize_text(person[\"name\"], \"synonyms.json\", context=\"ethnonym\")):\n",
    "                    for token in person[\"name\"].split(' '):\n",
    "                        eth_norm = normalize_text(token, \"synonyms.json\", context=\"ethnonym\")\n",
    "                        if token != eth_norm:\n",
    "                            if (person[\"ethnicities\"] == None) or (not (eth_norm in person[\"ethnicities\"])):\n",
    "                                if person[\"ethnicities\"] == None:\n",
    "                                    person[\"ethnicities\"] = eth_norm\n",
    "                                else:\n",
    "                                    person[\"ethnicities\"] = person[\"ethnicities\"] + ';' + eth_norm\n",
    "                    person[\"name\"] = normalize_text(person[\"name\"], \"synonyms.json\", context=\"ethnonym\")\n",
    "                else:\n",
    "                    for ethnonym in ethnonym_vocab:\n",
    "                        if ethnonym in person[\"name\"]:\n",
    "                            if person[\"ethnicities\"] == None:\n",
    "                                person[\"ethnicities\"] = ethnonym\n",
    "                            else:\n",
    "                                person[\"ethnicities\"] = person[\"ethnicities\"] + ';' + ethnonym\n",
    "                for phenotype in phenotype_vocab:\n",
    "                    if phenotype in normalize_text(person[key], \"synonyms.json\", context=\"characteristic\"):                    \n",
    "                        if person[\"phenotype\"] == None:\n",
    "                            person[\"phenotype\"] = phenotype\n",
    "                        else:\n",
    "                            person[\"phenotype\"] = person[\"phenotype\"] + ';' + phenotype\n",
    "                        if phenotype[-1] == 's':\n",
    "                            for token in person[\"name\"].split(' '):\n",
    "                                if normalize_text(token, \"synonyms.json\", context=\"characteristic\") == phenotype:\n",
    "                                    person[\"name\"] = person[\"name\"].replace(' ' + token, '')\n",
    "            elif key == \"ethnicities\":                \n",
    "                if person[key].find(';') == -1:\n",
    "                    person[key] = normalize_text(person[key], \"synonyms.json\", context=\"ethnonym\")                    \n",
    "                else:\n",
    "                    char_comp = person[key].split(';')\n",
    "                    person[key] = \"\"\n",
    "                    #strip out duplicate characteristics\n",
    "                    for char in char_comp:\n",
    "                        char = normalize_text(char, \"synonyms.json\", context=\"ethnonym\")                       \n",
    "                                          \n",
    "                        if not (char in person[key]):\n",
    "                            if person[key] == \"\":\n",
    "                                person[key] = char\n",
    "                            else:\n",
    "                                person[key] = person[key] + ';' + char\n",
    "            elif (key != \"id\") and (key != \"relationships\"):\n",
    "                if person[key].find(';') == -1:\n",
    "                    person[key] = normalize_text(person[key], \"synonyms.json\", context=\"characteristic\")\n",
    "                    person[key] = translate_characteristic(person[key], \"synonyms.json\", language)\n",
    "                else:\n",
    "                    char_comp = person[key].split(';')\n",
    "                    person[key] = \"\"\n",
    "                    #strip out duplicate characteristics\n",
    "                    for char in char_comp:\n",
    "                        char = normalize_text(char, \"synonyms.json\", context=\"characteristic\")                        \n",
    "                        char = translate_characteristic(char, \"synonyms.json\", language)                        \n",
    "                        if not (char in person[key]):\n",
    "                            if person[key] == \"\":\n",
    "                                person[key] = char\n",
    "                            else:\n",
    "                                person[key] = person[key] + ';' + char           \n",
    "        \n",
    "        #future improvement: find additional references for plural characteristics\n",
    "        \n",
    "        #count name frequency\n",
    "        if person[\"name\"] != None:\n",
    "            if person[\"name\"] in names:\n",
    "                name_counts[names.index(person['name'])] += 1\n",
    "            else:\n",
    "                names.append(person[\"name\"])\n",
    "                name_counts.append(1)   \n",
    "    \n",
    "    #disambiguate and merge people across the volume\n",
    "    redundant_records = []\n",
    "    merged_records = []    \n",
    "    for i in range(len(name_counts)):\n",
    "        if (name_counts[i] > .1 * len(images)) and (len(names[i].split(' ')) > 1) and (names[i] != \"Unknown principal\"):\n",
    "            records_to_merge = []            \n",
    "            for j in range(len(people)):\n",
    "                if people[j][\"name\"] == names[i]:\n",
    "                    redundant_records.append(people[j])\n",
    "                    records_to_merge.append(people[j])                    \n",
    "            merged_records.append(merge_records(records_to_merge))            \n",
    "    people = [person for person in people if person not in redundant_records]\n",
    "    for person in merged_records:\n",
    "        people.append(person)    \n",
    "    \n",
    "    print(\"People records enhanced and disambiguated.\")\n",
    "    \n",
    "    #reduce compound person IDs to single ID, add references field\n",
    "    people, events = compact_references(people, events)\n",
    "    \n",
    "    print(\"Single ID generated for each individual.\")\n",
    "    \n",
    "    #convert dictionaries into JSON    \n",
    "    with open(\"volume_records\\\\\" + volume_metadata[\"id\"] + \".json\", \"w\") as outfile:\n",
    "        outfile.write('{\\n\\\"volume\\\": \\n')\n",
    "        json.dump(volume_metadata, outfile)\n",
    "        outfile.write(',')\n",
    "        outfile.write('\\n\\\"images\\\": [\\n')\n",
    "        first_img = True\n",
    "        for image in images:\n",
    "            if first_img:\n",
    "                first_img = False\n",
    "            else:\n",
    "                outfile.write(\",\\n\")\n",
    "            json.dump(image, outfile)\n",
    "        outfile.write(\"\\n],\\n\")\n",
    "        outfile.write('\\n\\\"people\\\": [\\n')\n",
    "        first_person = True\n",
    "        for person in people:\n",
    "            if first_person:\n",
    "                first_person = False\n",
    "            else:\n",
    "                outfile.write(\",\\n\")            \n",
    "            json.dump(person, outfile)            \n",
    "        outfile.write(\"\\n],\\n\")\n",
    "        outfile.write(\"\\\"places\\\": [\\n\")\n",
    "        first_place = True\n",
    "        for place in places:\n",
    "            if first_place:\n",
    "                first_place = False\n",
    "            else:\n",
    "                outfile.write(\",\\n\")\n",
    "            json.dump(place, outfile)\n",
    "        outfile.write(\"\\n],\\n\")\n",
    "        outfile.write(\"\\\"events\\\": [\\n\")\n",
    "        first_event = True\n",
    "        for event in events:\n",
    "            if first_event:\n",
    "                first_event = False\n",
    "            else:\n",
    "                outfile.write(\",\\n\")\n",
    "            json.dump(event, outfile)\n",
    "        outfile.write(\"\\n]\\n\")\n",
    "        outfile.write('}')\n",
    "        \n",
    "    #dump validation dictionaries\n",
    "    with open(\"validation\\\\\" + volume_metadata[\"id\"] + \".json\", \"w\") as outfile:\n",
    "        outfile.write('{\\n\\\"entries\\\": [\\n')\n",
    "        first_entry = True\n",
    "        for entry in validation_dict_ALL:\n",
    "            if first_entry:\n",
    "                first_entry = False\n",
    "            else:\n",
    "                outfile.write(\",\\n\")\n",
    "            json.dump(entry, outfile)\n",
    "        outfile.write(\"\\n]\\n\")\n",
    "        outfile.write('}')\n",
    "            \n",
    "    print(\"JSON built, processing completed.\")\n",
    "            \n",
    "    return people, places, events, volume_metadata[\"id\"] + \"_ppe.json\", entitiesRunning, noCategoryRunning, validation_dict_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14193\\anaconda3\\lib\\site-packages\\spacy\\util.py:730: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'models/15834'\n",
      "Entities extracted.\n",
      "Entry entities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1033-1</td>\n",
       "      <td>Juana</td>\n",
       "      <td>PER</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1033-1</td>\n",
       "      <td>Esc.va</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1033-1</td>\n",
       "      <td>Domingo veinte y dos de [roto] y nueve</td>\n",
       "      <td>DATE</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1033-1</td>\n",
       "      <td>Thomas de Orvera</td>\n",
       "      <td>PER</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1033-1</td>\n",
       "      <td>Juana</td>\n",
       "      <td>PER</td>\n",
       "      <td>121</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index entry_no                             pred_entity pred_label  \\\n",
       "0      0   1033-1                                   Juana        PER   \n",
       "1      1   1033-1                                  Esc.va       CHAR   \n",
       "2      2   1033-1  Domingo veinte y dos de [roto] y nueve       DATE   \n",
       "3      3   1033-1                        Thomas de Orvera        PER   \n",
       "4      4   1033-1                                   Juana        PER   \n",
       "\n",
       "  pred_start pred_end  assigned  \n",
       "0         10       15      True  \n",
       "1         17       23      True  \n",
       "2         24       62      True  \n",
       "3         66       82      True  \n",
       "4        121      126      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry people:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '15834-1033-1-P4',\n",
       "  'name': 'Juan Joseph de Justis',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-1-P3',\n",
       "    'relationship_type': 'slave'}]},\n",
       " {'id': '15834-1033-1-P5',\n",
       "  'name': 'Joseph Salcedo',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-1-P1',\n",
       "    'relationship_type': 'godchild'}]},\n",
       " {'id': '15834-1033-1-P6',\n",
       "  'name': 'Ana de Santiago',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-1-P1',\n",
       "    'relationship_type': 'godchild'}]},\n",
       " {'id': '15834-1033-1-P7',\n",
       "  'name': 'mugger',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': None},\n",
       " {'id': '15834-1033-1-P1;15834-1033-1-P3',\n",
       "  'name': 'Juana',\n",
       "  'origin': None,\n",
       "  'ethnicities': 'Mina',\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'Esc.va;esclava',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-1-P5',\n",
       "    'relationship_type': 'godparent'},\n",
       "   {'related_person': '15834-1033-1-P6', 'relationship_type': 'godparent'},\n",
       "   {'related_person': '15834-1033-1-P4', 'relationship_type': 'enslaver'}]},\n",
       " {'id': '15834-1033-1-P2;15834-1033-1-P8',\n",
       "  'name': 'Thomas de Orvera',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': None}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry places:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Catedral de San Carlos Borromeo']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry events:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '15834-1033-1-E1',\n",
       "  'type': 'baptism',\n",
       "  'principal': '15834-1033-1-P1',\n",
       "  'date': '????-??-22',\n",
       "  'location': 'Catedral de San Carlos Borromeo',\n",
       "  'cleric': '15834-1033-1-P2'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncategorized characteristics:\n",
      "Entry entities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1033-2</td>\n",
       "      <td>Paula</td>\n",
       "      <td>PER</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1033-2</td>\n",
       "      <td>Esc.a</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1033-2</td>\n",
       "      <td>Juebes veinte y tres de feb.o de mil sietec.to...</td>\n",
       "      <td>DATE</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1033-2</td>\n",
       "      <td>Thomas de Orvera</td>\n",
       "      <td>PER</td>\n",
       "      <td>90</td>\n",
       "      <td>106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1033-2</td>\n",
       "      <td>Paula</td>\n",
       "      <td>PER</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index entry_no                                        pred_entity  \\\n",
       "0      0   1033-2                                              Paula   \n",
       "1      1   1033-2                                              Esc.a   \n",
       "2      2   1033-2  Juebes veinte y tres de feb.o de mil sietec.to...   \n",
       "3      3   1033-2                                   Thomas de Orvera   \n",
       "4      4   1033-2                                              Paula   \n",
       "\n",
       "  pred_label pred_start pred_end  assigned  \n",
       "0        PER         10       15      True  \n",
       "1       CHAR         17       22      True  \n",
       "2       DATE         23       86      True  \n",
       "3        PER         90      106      True  \n",
       "4        PER        145      150      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry people:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '15834-1033-2-P4',\n",
       "  'name': 'Juan Joseph',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'esc.s',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-2-P6',\n",
       "    'relationship_type': 'enslaver'}]},\n",
       " {'id': '15834-1033-2-P5',\n",
       "  'name': 'Maria Josepha',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'esc.s',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-2-P6',\n",
       "    'relationship_type': 'enslaver'}]},\n",
       " {'id': '15834-1033-2-P6',\n",
       "  'name': 'Capitan D. Luis Hurtado de Mendoza',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-2-P5',\n",
       "    'relationship_type': 'slave'},\n",
       "   {'related_person': '15834-1033-2-P4', 'relationship_type': 'slave'}]},\n",
       " {'id': '15834-1033-2-P7',\n",
       "  'name': 'Bartholome Rixo',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-2-P1',\n",
       "    'relationship_type': 'godchild'}]},\n",
       " {'id': '15834-1033-2-P1;15834-1033-2-P3',\n",
       "  'name': 'Paula',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'Esc.a',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-2-P7',\n",
       "    'relationship_type': 'godparent'}]},\n",
       " {'id': '15834-1033-2-P2;15834-1033-2-P8',\n",
       "  'name': 'Thomas de Orvera',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': None}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry places:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Catedral de San Carlos Borromeo']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry events:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '15834-1033-2-E1',\n",
       "  'type': 'baptism',\n",
       "  'principal': '15834-1033-2-P1',\n",
       "  'date': '1719-02-23',\n",
       "  'location': 'Catedral de San Carlos Borromeo',\n",
       "  'cleric': '15834-1033-2-P2'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncategorized characteristics:\n",
      "Entry entities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1033-3</td>\n",
       "      <td>Maria</td>\n",
       "      <td>PER</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1033-3</td>\n",
       "      <td>Esc.a</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1033-3</td>\n",
       "      <td>Miercoles prim.o de feb.o de mil siete.tos y d...</td>\n",
       "      <td>DATE</td>\n",
       "      <td>22</td>\n",
       "      <td>79</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1033-3</td>\n",
       "      <td>Thomas de Orvera</td>\n",
       "      <td>PER</td>\n",
       "      <td>83</td>\n",
       "      <td>99</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1033-3</td>\n",
       "      <td>Maria</td>\n",
       "      <td>PER</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index entry_no                                        pred_entity  \\\n",
       "0      0   1033-3                                              Maria   \n",
       "1      1   1033-3                                              Esc.a   \n",
       "2      2   1033-3  Miercoles prim.o de feb.o de mil siete.tos y d...   \n",
       "3      3   1033-3                                   Thomas de Orvera   \n",
       "4      4   1033-3                                              Maria   \n",
       "\n",
       "  pred_label pred_start pred_end  assigned  \n",
       "0        PER         10       15      True  \n",
       "1       CHAR         16       21      True  \n",
       "2       DATE         22       79      True  \n",
       "3        PER         83       99      True  \n",
       "4        PER        136      141      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry people:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '15834-1033-3-P4',\n",
       "  'name': 'Juan',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'esc.s',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-3-P6',\n",
       "    'relationship_type': 'enslaver'}]},\n",
       " {'id': '15834-1033-3-P5',\n",
       "  'name': 'Josepha',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'esc.s',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-3-P6',\n",
       "    'relationship_type': 'enslaver'}]},\n",
       " {'id': '15834-1033-3-P6',\n",
       "  'name': 'Capitan Antonio Benites',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-3-P5',\n",
       "    'relationship_type': 'slave'},\n",
       "   {'related_person': '15834-1033-3-P4', 'relationship_type': 'slave'}]},\n",
       " {'id': '15834-1033-3-P7',\n",
       "  'name': 'Ysabel Mendez',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-3-P1',\n",
       "    'relationship_type': 'godchild'}]},\n",
       " {'id': '15834-1033-3-P1;15834-1033-3-P3',\n",
       "  'name': 'Maria',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': 'Esc.a',\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': [{'related_person': '15834-1033-3-P7',\n",
       "    'relationship_type': 'godparent'}]},\n",
       " {'id': '15834-1033-3-P2;15834-1033-3-P8',\n",
       "  'name': 'Thomas de Orvera',\n",
       "  'origin': None,\n",
       "  'ethnicities': None,\n",
       "  'age': None,\n",
       "  'legitimacy': None,\n",
       "  'occupation': None,\n",
       "  'phenotype': None,\n",
       "  'status': None,\n",
       "  'titles': None,\n",
       "  'ranks': None,\n",
       "  'relationships': None}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry places:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Catedral de San Carlos Borromeo']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry events:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '15834-1033-3-E1',\n",
       "  'type': 'baptism',\n",
       "  'principal': '15834-1033-3-P1',\n",
       "  'date': '1719-02-01',\n",
       "  'location': 'Catedral de San Carlos Borromeo',\n",
       "  'cleric': '15834-1033-3-P2'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncategorized characteristics:\n",
      "Relationships linked.\n",
      "Events configured.\n",
      "People records enhanced and disambiguated.\n",
      "Single ID generated for each individual.\n",
      "JSON built, processing completed.\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "people, places, events, json_path, entities, noCategory, validation_list = process_volume(\"transcriptions\\\\15834.xml\", \"models/15834\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>entry_no</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1033-1</td>\n",
       "      <td>Juana</td>\n",
       "      <td>PER</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index entry_no pred_entity pred_label pred_start pred_end  assigned\n",
       "0      0   1033-1       Juana        PER         10       15      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14135, 7)\n",
      "------------------------------------------------\n",
      "Unassigned CHAR/RELs found:\n",
      "char_df shape: (1010, 7)\n",
      "rel_df shape: (172, 7)\n",
      "unassigned_df shape: (1182, 6)\n",
      "------------------------------------------------\n",
      "unassigned_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_no</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228-1</td>\n",
       "      <td>adverti</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1227-1</td>\n",
       "      <td>adverti</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1121-1</td>\n",
       "      <td>paroq.l</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1210-1</td>\n",
       "      <td>acien[roto] las part.das de los indios</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>23</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1202-4</td>\n",
       "      <td>part.da aunq</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entry_no                             pred_entity pred_label pred_start  \\\n",
       "0   1228-1                                 adverti       CHAR         14   \n",
       "1   1227-1                                 adverti       CHAR         14   \n",
       "2   1121-1                                 paroq.l       CHAR         19   \n",
       "3   1210-1  acien[roto] las part.das de los indios       CHAR         23   \n",
       "4   1202-4                            part.da aunq       CHAR         17   \n",
       "\n",
       "  pred_end  assigned  \n",
       "0       21     False  \n",
       "1       21     False  \n",
       "2       26     False  \n",
       "3       61     False  \n",
       "4       29     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noCategory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_no</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>assigned</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1033-2</td>\n",
       "      <td>h. l.16</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>151</td>\n",
       "      <td>158</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033-3</td>\n",
       "      <td>h. l.</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>142</td>\n",
       "      <td>147</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1034-4</td>\n",
       "      <td>lucumi</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>160</td>\n",
       "      <td>166</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1036-1</td>\n",
       "      <td>lucumi</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>225</td>\n",
       "      <td>231</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1037-1</td>\n",
       "      <td>Yngeniero mili</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>229</td>\n",
       "      <td>243</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entry_no     pred_entity pred_label  pred_start  pred_end  assigned category\n",
       "0   1033-2         h. l.16       CHAR         151       158     False     None\n",
       "1   1033-3           h. l.       CHAR         142       147     False     None\n",
       "2   1034-4          lucumi       CHAR         160       166     False     None\n",
       "3   1036-1          lucumi       CHAR         225       231     False     None\n",
       "4   1037-1  Yngeniero mili       CHAR         229       243     False     None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "unassigned_df = check_unassigned(entities, isVerbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def flatten_volume_json(path_to_volume_json, csv_root=''):\n",
    "    '''\n",
    "    flattens JSON record for a volume into six separate CSVs (volume, entries, people, relationships, places, and events)\n",
    "        path_to_volume_json: path to a volume JSON record\n",
    "        csv_root: specify directory for CSV output, including trailing /\n",
    "    \n",
    "        returns: root directory for CSVs\n",
    "    '''    \n",
    "    \n",
    "    with open(path_to_volume_json, encoding=\"utf-8\") as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "        \n",
    "    volume_id = data[\"volume\"][\"id\"]\n",
    "    \n",
    "    with open(csv_root + volume_id + \"_volume.csv\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        keys = 0\n",
    "        for key in data[\"volume\"]:\n",
    "            outfile.write(key)\n",
    "            keys += 1\n",
    "            if keys == len(data[\"volume\"]):\n",
    "                outfile.write('\\n')\n",
    "            else:\n",
    "                outfile.write(',')\n",
    "        keys = 0\n",
    "        for key in data[\"volume\"]:\n",
    "            outfile.write('\"' + data[\"volume\"][key] + '\"')            \n",
    "            keys += 1\n",
    "            if keys == len(data[\"volume\"]):\n",
    "                break\n",
    "            else:\n",
    "                outfile.write(',')\n",
    "                \n",
    "    with open(csv_root + volume_id + \"_entries.csv\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(\"entry id,entry text\\n\")\n",
    "        for image in data[\"images\"]:                        \n",
    "            image_id = volume_id + '-' + image[\"id\"]            \n",
    "            for entry in image[\"entries\"]:\n",
    "                entry_id = image_id + '-' + str(entry[\"id\"])\n",
    "                entry_text = entry[\"text\"]\n",
    "                outfile.write(entry_id + ',' + '\"' + entry_text + '\"\\n')\n",
    "                \n",
    "    with open(csv_root + volume_id + \"_people.csv\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(\"id,name,origin,ethnicity,age,legitimacy,occupation,phenotype,status,titles,ranks,references\\n\")\n",
    "        relationships = []\n",
    "        for person in data[\"people\"]:\n",
    "            for key in person:\n",
    "                if key == \"relationships\": \n",
    "                    if person[key] == None:\n",
    "                        continue\n",
    "                    for relationship in person[key]:                       \n",
    "                        if relationship[\"relationship_type\"] == \"godchild\":\n",
    "                            inverse_relationship_type = \"godparent\"\n",
    "                        elif relationship[\"relationship_type\"] == \"godparent\":\n",
    "                            inverse_relationship_type = \"godchild\"\n",
    "                        elif relationship[\"relationship_type\"] == \"grandparent\":\n",
    "                            inverse_relationship_type = \"grandchild\"\n",
    "                        elif relationship[\"relationship_type\"] == \"grandchild\":\n",
    "                            inverse_relationship_type = \"grandparent\"\n",
    "                        elif relationship[\"relationship_type\"] == \"parent\":\n",
    "                            inverse_relationship_type = \"child\"\n",
    "                        elif relationship[\"relationship_type\"] == \"child\":\n",
    "                            inverse_relationship_type = \"parent\"\n",
    "                        elif relationship[\"relationship_type\"] == \"slave\":\n",
    "                            inverse_relationship_type = \"enslaver\"\n",
    "                        elif relationship[\"relationship_type\"] == \"enslaver\":\n",
    "                            inverse_relationship_type = \"slave\"\n",
    "                        else:\n",
    "                            inverse_relationship_type = relationship[\"relationship_type\"]\n",
    "                            \n",
    "                        inverse_relationship = {\"from\": relationship[\"related_person\"], \"to\": person[\"id\"], \"type\": inverse_relationship_type}\n",
    "                        if not (inverse_relationship in relationships):\n",
    "                            relationships.append({\"from\": person[\"id\"], \"to\": relationship[\"related_person\"], \"type\": relationship[\"relationship_type\"]})\n",
    "                        \n",
    "                elif key == \"references\":\n",
    "                    references = person[key][0]\n",
    "                    for index in range(1, len(person[key])):\n",
    "                        references += ';' + person[key][index]\n",
    "                    outfile.write(references + '\\n')\n",
    "                elif person[key] == None:\n",
    "                    outfile.write(',')\n",
    "                else:\n",
    "                    outfile.write(person[key] + ',')\n",
    "                    \n",
    "    with open(csv_root + volume_id + \"_relationships.csv\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(\"from id,to id,relationship type\\n\")\n",
    "        for relationship in relationships:\n",
    "            outfile.write(relationship[\"from\"] + ',' + relationship[\"to\"] + ',' + relationship[\"type\"] + '\\n')\n",
    "            \n",
    "    with open(csv_root + volume_id + \"_places.csv\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(\"id,location\\n\")\n",
    "        for place in data[\"places\"]:\n",
    "            outfile.write(place[\"id\"] + ',' + place[\"location\"] + '\\n')\n",
    "            \n",
    "    with open(csv_root + volume_id + \"_events.csv\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(\"id,type,principal,date,location id,cleric\\n\")\n",
    "        for event in data[\"events\"]:\n",
    "            for key in event:\n",
    "                if event[key] == None:\n",
    "                    event[key] = ''\n",
    "            outfile.write(event[\"id\"] + ',' + event[\"type\"] + ',' + event[\"principal\"] + ',' + event[\"date\"] + ',' + event[\"location\"] + ',' + event[\"cleric\"] + '\\n')   \n",
    "                \n",
    "    return csv_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'volume_records/csv/'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "flatten_volume_json(\"volume_records/15834.json\", csv_root = \"volume_records/csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12-ssda-xml-parser.ipynb.\n",
      "Converted 31-collate-xml-entities-spans.ipynb.\n",
      "Converted 33-split-data.ipynb.\n",
      "Converted 41-generic-framework-for-spacy-training.ipynb.\n",
      "Converted 42-initial-model.ipynb.\n",
      "Converted 51-data-preprocessing.ipynb.\n",
      "Converted 52-unstructured-to-markup.ipynb.\n",
      "Converted 53-markup-to-spatial-historian.ipynb.\n",
      "Converted 54-utility-functions.ipynb.\n",
      "Converted 61-prodigy-output-training-demo.ipynb.\n",
      "Converted 62-full-model-application-demo.ipynb.\n",
      "Converted 63-pt-model-training.ipynb.\n",
      "Converted 64-es-model-training.ipynb.\n",
      "Converted 65-all-annotations-model-training.ipynb.\n",
      "Converted 66-es-guatemala-model-training.ipynb.\n",
      "Converted 67-death-and-birth-records-together.ipynb.\n",
      "Converted 70-exhaustive-training.ipynb.\n",
      "Converted 71-relationship-builder.ipynb.\n",
      "Converted 72-full-volume-processor.ipynb.\n",
      "Converted 73-table-output.ipynb.\n",
      "Converted 74-validation-visuals.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
