{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 41-generic-framework-for-spacy-training\n",
    "> Creating the framework for working with Spacy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**  The purpose of this notebook is provide basic code blocks for the following Spacy tasks:\n",
    "1. [Training](#Training) - train Spacy NER model with pre-labelled text \n",
    "2. [Testing](#Testing) - test Spacy NER model\n",
    "\n",
    "Based on https://spacy.io/usage/training#example-train-ner\n",
    "\n",
    "The functionality will also allow users to load and save models as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#no_test\n",
    "#dependencies\n",
    "\n",
    "#nlp packages\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "\n",
    "#ssda modules for testing\n",
    "from ssda_nlp.collate import genSpaCyInput\n",
    "\n",
    "# manipulation of tables/arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helpers\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code describes how we can train a Spacy model.  When loading the model, it expects a file directory or pretrained model (available through Spacy) from which to start from.  If one is not provided, a blank, untrained model will be loaded with some pre-existing pipeline components.  The following components are what are expected as inputs to the following modules.\n",
    "\n",
    "* training_data = list of tuples (string, JSON of labels).  The demo training data below shows the expected format.  \n",
    "* output_dir = \"/data/p_dsi/ssda/models/model_name\"\n",
    "* example model_name = \"es_ssda_sm\" per spaCy naming convention: https://spacy.io/models#conventions \n",
    "\n",
    "We can also indicate the languages of interest.  We'll be using Spanish and Portugese as indicated below:\n",
    "* Spanish language code = 'es'\n",
    "* Portuguese language code = 'pt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "spacy.util.fix_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>I like London and Berlin</td>\n",
       "      <td>London</td>\n",
       "      <td>LOC</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>I like London and Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>Who is Shaka Khan?</td>\n",
       "      <td>Shaka Khan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      text      entity   label  start  end\n",
       "0  12  I like London and Berlin      London     LOC      7   13\n",
       "1  12  I like London and Berlin      Berlin     LOC     18   24\n",
       "2  31        Who is Shaka Khan?  Shaka Khan  PERSON      7   17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "\n",
    "# demo training data\n",
    "TRAIN_DATA = [\n",
    "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
    "]\n",
    "\n",
    "# demo traing data in dataframe form\n",
    "test_ids = [12]*2 + [31]\n",
    "test_text = ['I like London and Berlin']*2 + ['Who is Shaka Khan?']\n",
    "test_ents = ['London', 'Berlin', 'Shaka Khan']\n",
    "test_types = ['LOC', 'LOC', 'PERSON']\n",
    "test_starts = [7,18,7]\n",
    "test_ends = [13,24,17]\n",
    "test_df = pd.DataFrame({'ID': test_ids, 'text':test_text, 'entity':test_ents, 'label':test_types,\n",
    "                        'start':test_starts, 'end':test_ends})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows you to load a model.  Note that the model is not a specific file, but a directory or a Spacy model name.  When we load a blank model, we go ahead and initialize the weights with the functionality defined in `begin_training`.  This will allow us to call `resume_training` for any model type during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def load_model(model=None, language=\"en\", verbose=False):\n",
    "    '''\n",
    "    Load the Spacy model or create blank model\n",
    "        model: (default None) directory of any existing model or named Spacy model\n",
    "        language: (default 'en') two-letter Spacy language code, default is English\n",
    "        verbose: (default False) boolean reflecting whether to print status of model loading\n",
    "            \n",
    "        returns: Spacy Language object\n",
    "    '''\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model \n",
    "        if verbose: print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        #Create new model\n",
    "        nlp = spacy.blank(language)  # create blank Language model\n",
    "        \n",
    "        # defaults to English, unless different language passed to function\n",
    "        if verbose: print(\"Created blank '\" + language)\n",
    "        \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `load model`\n",
    "Here, I'll make sure the execution paths work as expected.  I'll work on the the actual nlp object returned when I unit test `train_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'es_core_news_sm'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spacy.lang.es.Spanish"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "#Ensure loading the model works with spacy model\n",
    "nlp_from_spacy = load_model('es_core_news_sm', verbose=True)\n",
    "type(nlp_from_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "#Ensure loading the model works with blank model\n",
    "nlp_blank = load_model(language='en', verbose=True)\n",
    "type(nlp_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#Make sure verbose is working\n",
    "nlp_verb = load_model(model='es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The `train_model` function allows us to train the named entity recognition (NER) pipeline component of the NLP object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "\n",
    "def train_model(nlp, training_data, n_iter=100, dropout=0.5, compound_params=None, solver_params=None):\n",
    "    \n",
    "    '''\n",
    "    Train the `ner` component of the provided Language object (model)\n",
    "        nlp: Language object (model) - blank or pretrained.  Usually created by `load_model`.\n",
    "        training_data: pre-labelled training data in Spacy format\n",
    "        n_iter: (default 100)  Integer number of training iterations\n",
    "        dropout: (default 0.5)  Float value of ratio of dropout to prevent network memorization.\n",
    "        compound_params: (default None) dictionary of keys `start`, `end`, and `cp_rate` (defaults 4, 32, and 1.001).  Refer to the starting \n",
    "            number of elements in the batch (start), the maximum number of elements in a batch (end), and the multiplier of `start` to do the \n",
    "            compounding (cp_rate).  Pass in a dictionary of one or more of these keys to change those specific default parameters.\n",
    "        solver_params: (default None) dictionary of keys relating to the parameters of the Adam solver.  Allowable parameters include:\n",
    "            `learn_rate`, `b1`, `b2`, `L2`, `max_grad_norm`, with defaults 0.001, 0.9, 0.999, 1e-6, and 1.0.  See\n",
    "            https://github.com/explosion/spaCy/blob/master/spacy/_ml.py : `create_default_parameters` for more information.\n",
    "        \n",
    "        returns: trained Language object, pandas Dataframe object with losses per iteration\n",
    "    '''\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # use ner_init for blank models whose ner weights will need to be initialized later\n",
    "    ner_init = False\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        #ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(\"ner\", last=True)\n",
    "        ner_init = True\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    for _, annotations in training_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    \n",
    "    # only train NER\n",
    "    with nlp.disable_pipes(*other_pipes) and warnings.catch_warnings():\n",
    "        # show warnings for misaligned entity spans once\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "        \n",
    "        # initialize the weights if a blank model was passed in, otherwise, use existing weights.\n",
    "        if ner_init:\n",
    "            nlp.begin_training()\n",
    "        else:\n",
    "            nlp.resume_training()\n",
    "            \n",
    "        # set optimizer values to be the ones passed in if desired\n",
    "        allowable_params = ['learn_rate', 'b1', 'b2', 'L2', 'max_grad_norm']\n",
    "        if solver_params is not None:\n",
    "            for key, val in solver_params.items():\n",
    "                if key in allowable_params:\n",
    "                    setattr(nlp._optimizer, key, val)\n",
    "                else:\n",
    "                    raise ValueError('Key \"{0}\" not supported for solver. Only values {1} allowed'.format(key, allowable_params))\n",
    "        \n",
    "        # set compounding parameters to be passed in and ensure they are floats\n",
    "        cp_params = {'start': 4.0, 'end': 32.0, 'cp_rate': 1.001}\n",
    "        if compound_params is not None:\n",
    "            for key, val in compound_params.items():\n",
    "                if key in cp_params:\n",
    "                    cp_params[key] = float(compound_params[key])\n",
    "                else:\n",
    "                    raise ValueError('Key \"{0}\" not supported for compounding.  Only `start`, `end`, `cp_rate` allowed.'.format(key))\n",
    "        \n",
    "        # create dataframe to be returned\n",
    "        losses_df = pd.DataFrame(np.zeros(shape=(n_iter, 1)), columns=['epoch_loss'])\n",
    "        \n",
    "        # train batches of data for n_iter iterations\n",
    "        examples = []\n",
    "        for text, annots in training_data:    \n",
    "            examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "            #nlp.initialize(lambda: examples)\n",
    "        \n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(examples)\n",
    "            losses = {}\n",
    "            \n",
    "            # Create variable size minibatch\n",
    "            batches = minibatch(examples, size=compounding(cp_params['start'], cp_params['end'], cp_params['cp_rate']))\n",
    "            for batch in batches:                \n",
    "                #implement dropout decay?\n",
    "                nlp.update(\n",
    "                    batch,\n",
    "                    drop = dropout,  \n",
    "                    losses = losses,\n",
    "                )               \n",
    "                \n",
    "            # Update df with loss stats\n",
    "            losses_df.loc[itn, 'epoch_loss'] = losses['ner']\n",
    "     \n",
    "    return nlp, losses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `train_model`: reproducibility\n",
    "The purpose of this section is to explore how we can create reproducible models.  This should essentially come down to setting a seed, but let's make sure that is actually the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses from model 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.899999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.654533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.307241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.048512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.749421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8.319594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8.014254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.699785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.399865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.839060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch_loss\n",
       "0    9.899999\n",
       "1    9.654533\n",
       "2    9.307241\n",
       "3    9.048512\n",
       "4    8.749421\n",
       "5    8.319594\n",
       "6    8.014254\n",
       "7    7.699785\n",
       "8    7.399865\n",
       "9    6.839060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "#load load model 1\n",
    "nlp1 = load_model()\n",
    "nlp1, losses1 = train_model(nlp1, TRAIN_DATA, n_iter=10)\n",
    "print(\"Losses from model 1:\")\n",
    "display(losses1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should be as follows for an initial run:\n",
    "\n",
    "| epoch_loss |\n",
    "| ----------- |\n",
    "| 9.899999 |\n",
    "| 9.727400 |\n",
    "| 9.412539 |\n",
    "| 9.161101 |\n",
    "| 8.956753 |\n",
    "| 8.842925 |\n",
    "| 8.512361 |\n",
    "| 7.856238 |\n",
    "| 7.357123 |\n",
    "| 6.403693 |\n",
    "\n",
    "And they are!  However, this functionality may suffer from the behavior described in [this Spacy issue](https://github.com/explosion/spaCy/issues/5551) which we have an issue for [in our repo.](https://github.com/vanderbilt-data-science/ssda-entity-extraction/issues/84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `train_model`: solver parameters\n",
    "This uses the models previously created.  All tests below run as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "def validate_opt_params(opt, test_params):\n",
    "    '''\n",
    "    validate_opt_params: a simple function helper making sure the passed in parameters are the same as\n",
    "        what was used in the default Adam solver\n",
    "        opt: Spacy Language object (model) optimizer\n",
    "        test_params: dictionary of solver parameters to be tested against\n",
    "    '''\n",
    "    nlp_opt_params = {'learn_rate' : opt.learn_rate, 'b1':opt.b1, 'b2':opt.b2, 'L2':opt.L2,\n",
    "                      'max_grad_norm':opt.max_grad_norm}\n",
    "    \n",
    "    #fix test parameters to make sure they add any missing fields;\n",
    "    #this keeps the values of test_params if they also appear in nlp_opt_params\n",
    "    all_test_params = {**nlp_opt_params, **test_params}\n",
    "    \n",
    "    #make sure the result is correct\n",
    "    assert nlp_opt_params == all_test_params\n",
    "    \n",
    "    #show dataframe for sanity check\n",
    "    display(pd.DataFrame({'optimizer_params':nlp_opt_params, 'user_params':all_test_params}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_params</th>\n",
       "      <th>user_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn_rate</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_grad_norm</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               optimizer_params  user_params\n",
       "learn_rate             0.001000     0.001000\n",
       "b1                     0.900000     0.900000\n",
       "b2                     0.999000     0.999000\n",
       "L2                     0.000001     0.000001\n",
       "max_grad_norm          1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "# Original values for optimizer\n",
    "nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, solver_params = None)\n",
    "validate_opt_params(nlp2._optimizer, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_params</th>\n",
       "      <th>user_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn_rate</th>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.00300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_grad_norm</th>\n",
       "      <td>1.10000</td>\n",
       "      <td>1.10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               optimizer_params  user_params\n",
       "learn_rate              0.00300      0.00300\n",
       "b1                      0.80000      0.80000\n",
       "b2                      0.99000      0.99000\n",
       "L2                      0.00001      0.00001\n",
       "max_grad_norm           1.10000      1.10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "# Ensure that setting parameters works correctly\n",
    "solver_params_correct = {'learn_rate':0.003, 'b1':0.8, 'b2':0.99, 'L2':1e-5, 'max_grad_norm':1.1}\n",
    "nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, solver_params = solver_params_correct)\n",
    "validate_opt_params(nlp2._optimizer, solver_params_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_params</th>\n",
       "      <th>user_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn_rate</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_grad_norm</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               optimizer_params  user_params\n",
       "learn_rate             0.004000     0.004000\n",
       "b1                     0.900000     0.900000\n",
       "b2                     0.999000     0.999000\n",
       "L2                     0.000001     0.000001\n",
       "max_grad_norm          1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "# Ensure that it works for only a few specified parameters\n",
    "solver_params_sub = {'learn_rate':0.004}\n",
    "nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, solver_params = solver_params_sub)\n",
    "validate_opt_params(nlp2._optimizer, solver_params_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the result above.  When we trained the same model and modified only the learning rate, we actually maintained the same optimizer parameters from the previous call to the model.  This makes intuitive sense, and it is nice to see a confirmation of this result.  This is something we'll have to keep in mind, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_params</th>\n",
       "      <th>user_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn_rate</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_grad_norm</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               optimizer_params  user_params\n",
       "learn_rate             0.004000     0.004000\n",
       "b1                     0.900000     0.900000\n",
       "b2                     0.999000     0.999000\n",
       "L2                     0.000001     0.000001\n",
       "max_grad_norm          1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "# Make sure it works for the blank models too; first lets make sure it maintains the defaults\n",
    "solver_params_correct = {'learn_rate':0.004}\n",
    "nlp2, losses = train_model(nlp_blank, TRAIN_DATA, n_iter=5, solver_params = solver_params_correct)\n",
    "validate_opt_params(nlp2._optimizer, solver_params_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_params</th>\n",
       "      <th>user_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn_rate</th>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.00300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_grad_norm</th>\n",
       "      <td>1.10000</td>\n",
       "      <td>1.10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               optimizer_params  user_params\n",
       "learn_rate              0.00300      0.00300\n",
       "b1                      0.80000      0.80000\n",
       "b2                      0.99000      0.99000\n",
       "L2                      0.00001      0.00001\n",
       "max_grad_norm           1.10000      1.10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "# Make sure it works for the blank models for whole parameter list\n",
    "solver_params_correct = {'learn_rate':0.003, 'b1':0.8, 'b2':0.99, 'L2':1e-5, 'max_grad_norm':1.1}\n",
    "nlp2, losses = train_model(nlp_blank, TRAIN_DATA, n_iter=5, solver_params = solver_params_correct)\n",
    "validate_opt_params(nlp2._optimizer, solver_params_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bellcs1\\AppData\\Local\\Continuum\\anaconda3\\envs\\spacy-env\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Failed with exception: Key \"lr\" not supported for solver. Only values ['learn_rate', 'b1', 'b2', 'L2', 'max_grad_norm'] allowed\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "# Ensure it fails for wrong values\n",
    "solver_params_incorrect = {'lr':0.004}\n",
    "try:\n",
    "    nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, solver_params = solver_params_incorrect)\n",
    "except Exception as e:\n",
    "    warnings.warn('Failed with exception: {0}'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `train_model`: compounding\n",
    "Here, I'm just going to make sure the parameters are accepted correctly.  All tests appear to run correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#compounding parameters\n",
    "cmp_params_correct = {'start':5, 'end':20, 'cp_rate':2}\n",
    "cmp_params_sub = {'start':6}\n",
    "cmp_params_incorrect = {'begin':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#for full parameters\n",
    "nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, compound_params = cmp_params_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "#for partially specified parameters\n",
    "nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, compound_params = cmp_params_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bellcs1\\AppData\\Local\\Continuum\\anaconda3\\envs\\spacy-env\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Failed with exception: Key \"begin\" not supported for compounding.  Only `start`, `end`, `cp_rate` allowed.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "# incorrectly specified fields should fail\n",
    "try:\n",
    "    nlp2, losses = train_model(nlp_from_spacy, TRAIN_DATA, n_iter=5, compound_params = cmp_params_incorrect)\n",
    "except Exception as e:\n",
    "    warnings.warn('Failed with exception: {0}'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `train_model`: losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.074417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.676910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.471448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.819608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch_loss\n",
       "0   94.074417\n",
       "1   75.676910\n",
       "2   50.471448\n",
       "3   46.048500\n",
       "4   40.819608"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "nlp_blank = load_model()\n",
    "nlp_ls, loss_df = train_model(nlp_blank, TRAIN_DATA*10, n_iter=5)\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the train data has been replicated 10 times so that a batch size greater than 4 could be obtained.  Here, you see the total batch loss per iteration as `epoch_loss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Save model requires a directory and the model (pipeline) of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def save_model(nlp_model, output_dir):\n",
    "\n",
    "    '''\n",
    "    Save the Language object model to directory specified by `output_dir`\n",
    "       nlp_model: Language (pipeline) object\n",
    "       output_dir: output directory string - relative or absolute\n",
    "       returns: none - saves model to directory and prints directory\n",
    "    '''\n",
    "    \n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir(parents=True)\n",
    "        nlp_model.to_disk(output_dir)  # nlp.to_disk('/data/p_dsi/ssda/models/model_name')\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `save_model`\n",
    "By default, the line `output_dir.mkdir()` requires a `parents=True` statement if any parent files of the directory need to be created.  For example, if I need to create `models/test_model` and I don't have `models` already created, the call will fail.  Verified that this works will full filepaths as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to new_dir\\test_model\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "save_dir = 'new_dir/test_model'\n",
    "save_model(nlp2, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "blank_model = load_model(language=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to blank_spanish\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "save_model(blank_model, \"blank_spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "### Code development\n",
    "Here, we test the model perfomance using *labeled* data.  This function will return performance metrics as well as a dataframe of predictions.  The anticipated use case will be that we will operate on the original dataframe of labelled entities with the source identifier present.  I use the `test_df` created in the beginning cell with `TRAIN_DATA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_test\n",
    "# create new model\n",
    "nlp_en = load_model()\n",
    "nlp_en, loss_df = train_model(nlp_en, TRAIN_DATA, n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can process directly on this dataframe using `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _test_model(row, nlp_model, id_colname, text_colname):\n",
    "    '''\n",
    "    Internal helper function which uses the nlp model to predict the `text` rows of the dataframe and match with their ID.\n",
    "        *shouldn't be used directly; is used with an `apply` statement for a pandas DF\n",
    "        row: row of dataframe which contains at least columns `ID` and `text`\n",
    "        nlp_model: Spacy Language object (model) to perform predictions\n",
    "        id_colname: String name of the column where the ID is stored\n",
    "        text_colname: String name of the column where the text is stored\n",
    "        returns: Long pandas dataframe with columns reflecting entities recognized, entity types, and spans\n",
    "    '''\n",
    "    \n",
    "    doc = nlp_model(row[text_colname])\n",
    "    doc_ents = [(ents.text, ents.label_, ents.start_char, ents.end_char) for ents in doc.ents]\n",
    "    \n",
    "    # Make sure that actual entities were extracted or else, return None for everything\n",
    "    if doc_ents != []:\n",
    "        pred_ent_names, pred_ent_types, pred_ent_start, pred_ent_end = zip(*doc_ents)\n",
    "        res_sz = len(pred_ent_names)\n",
    "    else:\n",
    "        pred_ent_names, pred_ent_types, pred_ent_start, pred_ent_end = None, None, None, None\n",
    "        res_sz = 1\n",
    "    \n",
    "    df_res = pd.DataFrame({id_colname: [row[id_colname]]* res_sz, #to fix when doc_ents is None\n",
    "                           'pred_entity': pred_ent_names,\n",
    "                           'pred_label': pred_ent_types,\n",
    "                           'pred_start': pred_ent_start,\n",
    "                           'pred_end': pred_ent_end})\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>I like London and Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Who is Shaka Khan?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      text\n",
       "0  12  I like London and Berlin\n",
       "2  31        Who is Shaka Khan?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>London</td>\n",
       "      <td>LOC</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Shaka Khan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID pred_entity pred_label  pred_start  pred_end\n",
       "0  12      London        LOC           7        13\n",
       "1  12      Berlin        LOC          18        24\n",
       "2  31  Shaka Khan     PERSON           7        17"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "# Get unique entries in the test_df\n",
    "entries_df = test_df[['ID', 'text']].drop_duplicates()\n",
    "display(entries_df.head())\n",
    "\n",
    "#Get predicted entities and show\n",
    "preds = entries_df.apply(_test_model, axis=1, args=[nlp_en, 'ID', 'text']).tolist()\n",
    "preds_df = pd.concat(preds, ignore_index=True)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's interesting is that now, this `preds_df` can be joined with `test_df`, and some further analysis of the performance can be done.  An example of this join is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>I like London and Berlin</td>\n",
       "      <td>London</td>\n",
       "      <td>LOC</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>London</td>\n",
       "      <td>LOC</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>I like London and Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Who is Shaka Khan?</td>\n",
       "      <td>Shaka Khan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>Shaka Khan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      text      entity   label  start  end pred_entity  \\\n",
       "0  12  I like London and Berlin      London     LOC      7   13      London   \n",
       "1  12  I like London and Berlin      Berlin     LOC     18   24      Berlin   \n",
       "2  31        Who is Shaka Khan?  Shaka Khan  PERSON      7   17  Shaka Khan   \n",
       "\n",
       "  pred_label  pred_start  pred_end  \n",
       "0        LOC           7        13  \n",
       "1        LOC          18        24  \n",
       "2     PERSON           7        17  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no_test\n",
    "res_df = pd.merge(test_df, preds_df, left_on=['ID', 'entity', 'label'], right_on=['ID', 'pred_entity', 'pred_label'], how='outer')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module code version\n",
    "Here, the `evaluate` and `Scorer` have been utilized straightforwardly from Spacy.\n",
    "- For more information on `evaluate`, see here:  [Language.evaluate](https://spacy.io/api/language#evaluate)\n",
    "- For more information on `Scorer`, see here: [Scorer](https://spacy.io/api/scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# test the trained model\n",
    "def test_model(nlp_model, testing_df, id_colname, text_colname, score_model=True):    \n",
    "    '''\n",
    "    Use the model to predict the entities and labels of the testing data using the model specified; optionally return precision/recall metrics \n",
    "        nlp_model: nlp object to be evaluated\n",
    "        testing_df: original dataframe with columns `ID`, `text`, `entity*`, `label*`, `start*`, and `end*`.\n",
    "            `ID`: identifier for each entry/text\n",
    "            `text: the text of each text\n",
    "            `entity`: the person, place, etc within the text to be identified (note: this data frame will be long since there can be\n",
    "                multiple entities for the same entry)\n",
    "            `label`: the entity type (e.g., PER, LOC)\n",
    "            `start`: starting character of the entity in the entry\n",
    "            `end`: one past the ending character of the entity in the entry\n",
    "            `*` indicates columns that are required only if score_model=True\n",
    "        id_colname: String name of the column where the entry ID is stored\n",
    "        text_colname: String name of the column where the text is stored\n",
    "        score_model: (default True) boolean indicating whether to return precision/recall metrics associated with the model predictions.  Must pass\n",
    "            *'ed columns in the dataframe.\n",
    "\n",
    "        returns: dataframe of prediction results,\n",
    "                 dataframe of overall precision, recall, and fscore (None if score_model is False)\n",
    "                 dataframe of per-entity precision, recall, and fscore (None if score_model is False)\n",
    "    '''\n",
    "    \n",
    "    # get unique entries/texts from the dataframe as a dataframe\n",
    "    # using id_colname and text_colname both here should be OK as they are 1:1\n",
    "    unique_entries_df = testing_df[[id_colname, text_colname]].drop_duplicates()\n",
    "    \n",
    "    # Get predicted entities\n",
    "    preds = unique_entries_df.apply(_test_model, axis=1, args=[nlp_model, id_colname, text_colname]).tolist()\n",
    "    preds_df = pd.concat(preds, ignore_index=True)\n",
    "    \n",
    "    # Get model performance\n",
    "    pred_metrics = None\n",
    "    per_ent_metrics = None\n",
    "    \n",
    "    if score_model:\n",
    "        spacy_test_data = genSpaCyInput(testing_df)\n",
    "        \n",
    "        examples = []\n",
    "        for text, annots in spacy_test_data:    \n",
    "            examples.append(Example.from_dict(nlp_model.make_doc(text), annots))\n",
    "        \n",
    "        nlp_scorer = nlp_model.evaluate(examples)\n",
    "\n",
    "        # Build dataframe of results\n",
    "        pred_metrics = pd.DataFrame({'precision': [nlp_scorer['ents_p'] * 100],\n",
    "                                     'recall': [nlp_scorer['ents_r'] * 100],\n",
    "                                     'f_score': [nlp_scorer['ents_f'] * 100],\n",
    "                                    })\n",
    "\n",
    "        per_ent_metrics = pd.DataFrame({**nlp_scorer['ents_per_type']})\n",
    "    \n",
    "    return preds_df, pred_metrics, per_ent_metrics    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing: `test_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see the expected use case, performance of the model, and expected outputs.  Here, we use a blank english model and train it 10-50 iterations.  I've verified that when no entities are extracted, the code still works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted entities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID pred_entity pred_label pred_start pred_end\n",
       "0  12        None       None       None     None\n",
       "1  31        None       None       None     None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall  f_score\n",
       "0        0.0     0.0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity-specific performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOC  PERSON\n",
       "p  0.0     0.0\n",
       "r  0.0     0.0\n",
       "f  0.0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "#load and train model\n",
    "nlp_en = load_model(verbose=False)\n",
    "nlp_en, losses = train_model(nlp_en, TRAIN_DATA, n_iter=30)\n",
    "\n",
    "#test model\n",
    "ent_preds_df, metrics_df, per_ent_metrics = test_model(nlp_en, test_df, 'ID', 'text')\n",
    "\n",
    "#show performance\n",
    "print('Predicted entities:')\n",
    "display(ent_preds_df)\n",
    "\n",
    "print('\\nOverall performance:')\n",
    "display(metrics_df)\n",
    "\n",
    "print('\\nEntity-specific performance:')\n",
    "display(per_ent_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I try it without the scorer and with a subset of the columns of the dataframe, which works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted entities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>London</td>\n",
       "      <td>LOC</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID pred_entity pred_label pred_start pred_end\n",
       "0  12      London        LOC          7       13\n",
       "1  31        None       None       None     None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "#test model\n",
    "ent_preds_df,_,_ = test_model(nlp_en, test_df[['ID', 'text']], 'ID', 'text', score_model=False)\n",
    "\n",
    "#show performance\n",
    "print('Predicted entities:')\n",
    "display(ent_preds_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training losses:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.899999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.730163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.271213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.219586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.519299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch_loss\n",
       "0    9.899999\n",
       "1    9.730163\n",
       "2    9.271213\n",
       "3    9.219586\n",
       "4    8.519299"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_test\n",
    "save_dir = 'test_dir/en_model'\n",
    "\n",
    "#load and train model\n",
    "new_model = load_model(verbose=False)\n",
    "new_model, losses = train_model(new_model, TRAIN_DATA, n_iter=50)\n",
    "print('Training losses:')\n",
    "display(losses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>London</td>\n",
       "      <td>LOC</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Shaka Khan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID pred_entity pred_label  pred_start  pred_end\n",
       "0  12      London        LOC           7        13\n",
       "1  12      Berlin        LOC          18        24\n",
       "2  31  Shaka Khan     PERSON           7        17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision     recall    f_score\n",
       "0  66.666667  66.666667  66.666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per entity performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LOC  PERSON\n",
       "p  100.0     0.0\n",
       "r  100.0     0.0\n",
       "f  100.0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to test_dir\\en_model\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "#test model\n",
    "pred_df, mets_df, per_ent_df = test_model(new_model, test_df, 'ID', 'text')\n",
    "print('Entity predictions:')\n",
    "display(preds_df)\n",
    "print('\\nOverall performance:')\n",
    "display(mets_df)\n",
    "print('\\nPer entity performance:')\n",
    "display(per_ent_df)\n",
    "\n",
    "#save model\n",
    "save_model(new_model, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12-ssda-xml-parser.ipynb.\n",
      "Converted 31-collate-xml-entities-spans.ipynb.\n",
      "Converted 33-split-data.ipynb.\n",
      "Converted 41-generic-framework-for-spacy-training.ipynb.\n",
      "Converted 42-initial-model.ipynb.\n",
      "Converted 51-data-preprocessing.ipynb.\n",
      "Converted 52-unstructured-to-markup.ipynb.\n",
      "Converted 53-markup-to-spatial-historian.ipynb.\n",
      "Converted 54-utility-functions.ipynb.\n",
      "Converted 61-prodigy-output-training-demo.ipynb.\n",
      "Converted 62-full-model-application-demo.ipynb.\n",
      "Converted 63-pt-model-training.ipynb.\n",
      "Converted 64-es-model-training.ipynb.\n",
      "Converted 65-all-annotations-model-training.ipynb.\n",
      "Converted 66-es-guatemala-model-training.ipynb.\n",
      "Converted 67-death-and-birth-records-together.ipynb.\n",
      "Converted 70-exhaustive-training.ipynb.\n",
      "Converted 71-relationship-builder.ipynb.\n",
      "Converted 72-full-volume-processor.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#no_test\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
